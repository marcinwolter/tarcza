{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8FuA2IG1Kf/dE5qaZVvOP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwolter/tarcza/blob/main/tarcza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Rekonstrukcja współrzędnych punktu trafienia w tarczę**\n",
        "*Marcin Wolter*\n",
        "\n",
        "*29.12.2024*\n",
        "\n",
        "Tarcza ma promień *radius*, cztery mikrofony rozmieszczone są w odległości *R_mic* od środka tarczy. Generowane jest *num_points* trafień w tarczę. Dodany jest błąd pomiaru czasu.\n",
        "\n",
        "Rekonstrukcja punktu trafienia przeprowadzana jest na dwa sposoby:\n",
        "* algebraiczny, rozwiązanie układu równań za pomocą *scipy.optimize.fsolve*. Uzyskujemy cztery rozwiązania, wyciągamy z nich średnią.\n",
        "UWAGA! Zamiast używać numerycznego rozwiązania równań *fsolve* należy rozwiązać je algebraicznie (da się zrobić).\n",
        "* za pomocą sieci neuronowej, która rekonstruuje punkt trafienia na podstawie czasów zarejestrowanych przez mikrofony."
      ],
      "metadata": {
        "id": "jr9EBAfW2rA3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wjjaybRKmoDE"
      },
      "outputs": [],
      "source": [
        "# prompt: random points on a plane within the radius R\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "\n",
        "# speed of sound\n",
        "v_s = 34000 # cm/s\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# algebraic calculation\n",
        "\n",
        "def algebraic_calc(out_meas, R_mic):\n",
        "\n",
        "  out_pred = np.zeros((len(out_meas),2))\n",
        "  for i in range(len(out_meas)):\n",
        "\n",
        "    t0 = out_meas[i]\n",
        "\n",
        "    #Calculate three crossing points and take an average\n",
        "    def equations(vars, R, d0, d1, d2, d3, i_drop):\n",
        "      x, y, d = vars\n",
        "      eq0 = (x - R)**2 + y**2 - (d0+d)**2\n",
        "      eq1 = x**2 + (y + R)**2 - (d1+d)**2\n",
        "      eq2 = (x + R)**2 + y**2 - (d2+d)**2\n",
        "      eq3 = x**2 + (y - R)**2 - (d3+d)**2\n",
        "      if i_drop == 0:\n",
        "        return [eq1, eq2, eq3]\n",
        "      elif i_drop == 1:\n",
        "        return [eq0, eq2, eq3]\n",
        "      elif i_drop == 2:\n",
        "        return [eq0, eq1, eq3]\n",
        "      return [eq0, eq1, eq2]\n",
        "\n",
        "    # Calculate distances\n",
        "    dd0 = v_s * t0\n",
        "\n",
        "    # Initial guess for (x, y, d)\n",
        "    initial_guess = (0, 0, 0)\n",
        "\n",
        "    # Solve the system of equations\n",
        "    x_out = np.zeros((len(t0),2))\n",
        "    for k in range(len(t0)):\n",
        "      x, y, d = fsolve(equations, initial_guess, args=(R_mic, dd0[0], dd0[1], dd0[2], dd0[3], k))\n",
        "      x_out[k,0] = -y\n",
        "      x_out[k,1] = x\n",
        "    x_mean = np.mean(x_out, axis=0)\n",
        "\n",
        "    out_pred[i,0] = x_mean[0]\n",
        "    out_pred[i,1] = x_mean[1]\n",
        "\n",
        "  return out_pred\n"
      ],
      "metadata": {
        "id": "Jt5FtBlIGoHn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def monte_carlo_circle(R, R_mic, time_error, num_points):\n",
        "    \"\"\"\n",
        "    Points within a circle of radius R using Monte Carlo simulation.\n",
        "\n",
        "    Args:\n",
        "        R: The radius of the circle.\n",
        "        num_points: The number of random points to generate.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "            - x, y of the true points\n",
        "            - four times measured (one is zero)\n",
        "            - rotation flag\n",
        "    \"\"\"\n",
        "    # microphone positions\n",
        "    xy_mic = np.array([[0, R_mic], [R_mic, 0], [0, -R_mic], [-R_mic,0]])\n",
        "    time = np.zeros((4))\n",
        "\n",
        "    out_true = np.zeros((num_points, 2))\n",
        "    out_measured = np.zeros((num_points, 4))\n",
        "    rot_flag = np.zeros((num_points))\n",
        "    inside_circle = 0\n",
        "\n",
        "    while inside_circle < num_points:\n",
        "        x = random.uniform(-R, R)\n",
        "        y = random.uniform(-R, R)\n",
        "        distance2 = x*x + y*y\n",
        "        if distance2 <= R*R:\n",
        "          for i in range(4):\n",
        "            time[i] = np.sqrt((xy_mic[i,0]-x)**2 + (xy_mic[i,1]-y)**2)/v_s\n",
        "            # introduce error\n",
        "            time[i] = max(0,time[i]+random.gauss(0,time_error))\n",
        "\n",
        "          i_min = np.argmin(time)\n",
        "\n",
        "          for k in range(4):\n",
        "            out_measured[inside_circle, k] = time[k]-time[i_min]\n",
        "          rot_flag[inside_circle] = i_min\n",
        "\n",
        "          out_true[inside_circle, 0] = x\n",
        "          out_true[inside_circle, 1] = y\n",
        "\n",
        "          inside_circle += 1\n",
        "          #print(f\"point: {x, y, inside_circle}\")\n",
        "\n",
        "\n",
        "\n",
        "    return out_true, out_measured, rot_flag\n",
        "\n"
      ],
      "metadata": {
        "id": "0zXw3yqCAOhG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neural network regression out_measured -> out_true\n",
        "def regression(out_measured, out_true):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(out_measured, out_true,\n",
        "                                                    random_state=1)\n",
        "\n",
        "    #see https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
        "    regr = MLPRegressor(hidden_layer_sizes=(30,30), activation='relu', solver='adam',\n",
        "                        alpha=0.0001, batch_size='auto', learning_rate='adaptive',\n",
        "                        learning_rate_init=0.001, random_state=33, tol=0.0001,\n",
        "                        verbose=True, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
        "                        early_stopping=True, validation_fraction=0.2, n_iter_no_change=100,\n",
        "                        max_iter = 10000)\n",
        "    regr.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Regression score: \",regr.score(X_test, y_test))\n",
        "\n",
        "    return regr\n"
      ],
      "metadata": {
        "id": "B0HixMWq70zC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "radius = 5.0  # Set the radius of the circle\n",
        "num_points = 10000 # 10000  # Set the number of random points\n",
        "R_mic = 7.\n",
        "time_error = 0.000002 # 0.00001\n",
        "\n",
        "out_true, out_meas, rot_flag = monte_carlo_circle(radius, R_mic, time_error, num_points)\n",
        "#print(f\"true: {out_true[0:4]}\")\n",
        "#print(f\"meas: {out_meas[0:4]}\")\n",
        "#print(f\"rot: {rot_flag[0:4]}\")\n",
        "#print(out_true.shape, out_meas.shape, rot_flag.shape)\n",
        "\n",
        "# algebraic calculation\n",
        "out_pred = algebraic_calc(out_meas, R_mic)\n",
        "\n",
        "print(\"Algebraic calculation\")\n",
        "print(\"true: \")\n",
        "print(out_true[0:4])\n",
        "print(\"predicted:\")\n",
        "print(out_pred[0:4])\n",
        "print(\"Algebraic calc score: \",sklearn.metrics.r2_score(out_true, out_pred))\n",
        "print(\" \")\n",
        "\n",
        "\n",
        "\n",
        "#Regression using neural network\n",
        "print(\"Neural network\")\n",
        "regr = regression(out_meas, out_true)\n",
        "\n",
        "\n",
        "# Plot the 'loss_curve_' protery on model to see how well we are learning over the iterations\n",
        "pd.DataFrame(regr.loss_curve_).plot()\n",
        "\n",
        "# save the model to disk\n",
        "#filename = 'regr_model.sav'\n",
        "#pickle.dump(regr, open(filename, 'wb'))\n",
        "\n",
        "# load the model from disk\n",
        "#regr = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "# Test regressor on the new data\n",
        "out_true, out_meas, rot_flag = monte_carlo_circle(radius, R_mic, time_error, num_points)\n",
        "predicted = regr.predict(out_meas)\n",
        "\n",
        "print(\"true: \")\n",
        "print(out_true[0:4])\n",
        "print(\"predicted:\")\n",
        "print(predicted[0:4])\n",
        "print(\"Regression score: \",regr.score(out_meas, out_true))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1DsU4BizxAdX",
        "outputId": "998465f0-c185-46b5-bf16-50b23cc220fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algebraic calculation\n",
            "true: \n",
            "[[ 3.29325954 -0.16483587]\n",
            " [-2.24847764  1.84445235]\n",
            " [ 0.8639155  -2.18452847]\n",
            " [ 2.84472001 -3.59384768]]\n",
            "predicted:\n",
            "[[ 3.21100565 -0.12607928]\n",
            " [-2.24605265  1.90433701]\n",
            " [ 0.90628493 -2.12825082]\n",
            " [ 2.88259294 -3.61343939]]\n",
            "Algebraic calc score:  0.9994950630869053\n",
            " \n",
            "Neural network\n",
            "Iteration 1, loss = 3.14996891\n",
            "Validation score: -0.000155\n",
            "Iteration 2, loss = 3.14872495\n",
            "Validation score: -0.000054\n",
            "Iteration 3, loss = 3.14759374\n",
            "Validation score: -0.000561\n",
            "Iteration 4, loss = 3.14741310\n",
            "Validation score: -0.000200\n",
            "Iteration 5, loss = 3.14864988\n",
            "Validation score: -0.000272\n",
            "Iteration 6, loss = 3.14740483\n",
            "Validation score: -0.000154\n",
            "Iteration 7, loss = 3.14755854\n",
            "Validation score: -0.000399\n",
            "Iteration 8, loss = 3.14746644\n",
            "Validation score: -0.000533\n",
            "Iteration 9, loss = 3.14745189\n",
            "Validation score: -0.000082\n",
            "Iteration 10, loss = 3.14757720\n",
            "Validation score: -0.000230\n",
            "Iteration 11, loss = 3.14859653\n",
            "Validation score: -0.000122\n",
            "Iteration 12, loss = 3.14808456\n",
            "Validation score: -0.000398\n",
            "Iteration 13, loss = 3.14758865\n",
            "Validation score: -0.000437\n",
            "Iteration 14, loss = 3.14726755\n",
            "Validation score: -0.000166\n",
            "Iteration 15, loss = 3.14712719\n",
            "Validation score: -0.000216\n",
            "Iteration 16, loss = 3.14719065\n",
            "Validation score: -0.000544\n",
            "Iteration 17, loss = 3.14810189\n",
            "Validation score: -0.000298\n",
            "Iteration 18, loss = 3.14772341\n",
            "Validation score: -0.000272\n",
            "Iteration 19, loss = 3.14754064\n",
            "Validation score: -0.000019\n",
            "Iteration 20, loss = 3.14701604\n",
            "Validation score: -0.000264\n",
            "Iteration 21, loss = 3.14779843\n",
            "Validation score: -0.000124\n",
            "Iteration 22, loss = 3.14729265\n",
            "Validation score: -0.000138\n",
            "Iteration 23, loss = 3.14742114\n",
            "Validation score: -0.000180\n",
            "Iteration 24, loss = 3.14730479\n",
            "Validation score: -0.000353\n",
            "Iteration 25, loss = 3.14707847\n",
            "Validation score: -0.000015\n",
            "Iteration 26, loss = 3.14725406\n",
            "Validation score: -0.000063\n",
            "Iteration 27, loss = 3.14768812\n",
            "Validation score: -0.000208\n",
            "Iteration 28, loss = 3.14680583\n",
            "Validation score: 0.000030\n",
            "Iteration 29, loss = 3.14751604\n",
            "Validation score: -0.000151\n",
            "Iteration 30, loss = 3.14683409\n",
            "Validation score: -0.000057\n",
            "Iteration 31, loss = 3.14702927\n",
            "Validation score: -0.000096\n",
            "Iteration 32, loss = 3.14738448\n",
            "Validation score: 0.000086\n",
            "Iteration 33, loss = 3.14740484\n",
            "Validation score: -0.000019\n",
            "Iteration 34, loss = 3.14690408\n",
            "Validation score: 0.000016\n",
            "Iteration 35, loss = 3.14764236\n",
            "Validation score: -0.000064\n",
            "Iteration 36, loss = 3.14745118\n",
            "Validation score: -0.000083\n",
            "Iteration 37, loss = 3.14698686\n",
            "Validation score: -0.000048\n",
            "Iteration 38, loss = 3.14704730\n",
            "Validation score: -0.000364\n",
            "Iteration 39, loss = 3.14677207\n",
            "Validation score: -0.000023\n",
            "Iteration 40, loss = 3.14688147\n",
            "Validation score: -0.000067\n",
            "Iteration 41, loss = 3.14727805\n",
            "Validation score: 0.000251\n",
            "Iteration 42, loss = 3.14721567\n",
            "Validation score: 0.000149\n",
            "Iteration 43, loss = 3.14663326\n",
            "Validation score: -0.000032\n",
            "Iteration 44, loss = 3.14716344\n",
            "Validation score: 0.000044\n",
            "Iteration 45, loss = 3.14673758\n",
            "Validation score: 0.000201\n",
            "Iteration 46, loss = 3.14660471\n",
            "Validation score: -0.000108\n",
            "Iteration 47, loss = 3.14661100\n",
            "Validation score: 0.000150\n",
            "Iteration 48, loss = 3.14647477\n",
            "Validation score: 0.000214\n",
            "Iteration 49, loss = 3.14606994\n",
            "Validation score: -0.000042\n",
            "Iteration 50, loss = 3.14625082\n",
            "Validation score: 0.000170\n",
            "Iteration 51, loss = 3.14672685\n",
            "Validation score: -0.000103\n",
            "Iteration 52, loss = 3.14595670\n",
            "Validation score: 0.000203\n",
            "Iteration 53, loss = 3.14664008\n",
            "Validation score: -0.000058\n",
            "Iteration 54, loss = 3.14642318\n",
            "Validation score: 0.000171\n",
            "Iteration 55, loss = 3.14609616\n",
            "Validation score: 0.000274\n",
            "Iteration 56, loss = 3.14598591\n",
            "Validation score: 0.000205\n",
            "Iteration 57, loss = 3.14633024\n",
            "Validation score: 0.000251\n",
            "Iteration 58, loss = 3.14596372\n",
            "Validation score: 0.000236\n",
            "Iteration 59, loss = 3.14575815\n",
            "Validation score: 0.000412\n",
            "Iteration 60, loss = 3.14560819\n",
            "Validation score: 0.000276\n",
            "Iteration 61, loss = 3.14658674\n",
            "Validation score: 0.000551\n",
            "Iteration 62, loss = 3.14583028\n",
            "Validation score: 0.000171\n",
            "Iteration 63, loss = 3.14556007\n",
            "Validation score: 0.000256\n",
            "Iteration 64, loss = 3.14564797\n",
            "Validation score: 0.000103\n",
            "Iteration 65, loss = 3.14503230\n",
            "Validation score: 0.000502\n",
            "Iteration 66, loss = 3.14522857\n",
            "Validation score: 0.000443\n",
            "Iteration 67, loss = 3.14556840\n",
            "Validation score: 0.000472\n",
            "Iteration 68, loss = 3.14520362\n",
            "Validation score: 0.000472\n",
            "Iteration 69, loss = 3.14493955\n",
            "Validation score: 0.000253\n",
            "Iteration 70, loss = 3.14557302\n",
            "Validation score: 0.000257\n",
            "Iteration 71, loss = 3.14492789\n",
            "Validation score: 0.000635\n",
            "Iteration 72, loss = 3.14482077\n",
            "Validation score: 0.000629\n",
            "Iteration 73, loss = 3.14488110\n",
            "Validation score: 0.000654\n",
            "Iteration 74, loss = 3.14491524\n",
            "Validation score: 0.000124\n",
            "Iteration 75, loss = 3.14527911\n",
            "Validation score: 0.000408\n",
            "Iteration 76, loss = 3.14467031\n",
            "Validation score: 0.000945\n",
            "Iteration 77, loss = 3.14483834\n",
            "Validation score: 0.000751\n",
            "Iteration 78, loss = 3.14413614\n",
            "Validation score: 0.000939\n",
            "Iteration 79, loss = 3.14411034\n",
            "Validation score: 0.000892\n",
            "Iteration 80, loss = 3.14494807\n",
            "Validation score: 0.000832\n",
            "Iteration 81, loss = 3.14390021\n",
            "Validation score: 0.001306\n",
            "Iteration 82, loss = 3.14462577\n",
            "Validation score: 0.000792\n",
            "Iteration 83, loss = 3.14361856\n",
            "Validation score: 0.001245\n",
            "Iteration 84, loss = 3.14296854\n",
            "Validation score: 0.000950\n",
            "Iteration 85, loss = 3.14333519\n",
            "Validation score: 0.001267\n",
            "Iteration 86, loss = 3.14327984\n",
            "Validation score: 0.001506\n",
            "Iteration 87, loss = 3.14336839\n",
            "Validation score: 0.001649\n",
            "Iteration 88, loss = 3.14335019\n",
            "Validation score: 0.001465\n",
            "Iteration 89, loss = 3.14293489\n",
            "Validation score: 0.001535\n",
            "Iteration 90, loss = 3.14242875\n",
            "Validation score: 0.001401\n",
            "Iteration 91, loss = 3.14190783\n",
            "Validation score: 0.001821\n",
            "Iteration 92, loss = 3.14182629\n",
            "Validation score: 0.001339\n",
            "Iteration 93, loss = 3.14169984\n",
            "Validation score: 0.001814\n",
            "Iteration 94, loss = 3.14136207\n",
            "Validation score: 0.001811\n",
            "Iteration 95, loss = 3.14102544\n",
            "Validation score: 0.001988\n",
            "Iteration 96, loss = 3.14139464\n",
            "Validation score: 0.001466\n",
            "Iteration 97, loss = 3.14046037\n",
            "Validation score: 0.002384\n",
            "Iteration 98, loss = 3.14018824\n",
            "Validation score: 0.001997\n",
            "Iteration 99, loss = 3.13979610\n",
            "Validation score: 0.002152\n",
            "Iteration 100, loss = 3.13969935\n",
            "Validation score: 0.002541\n",
            "Iteration 101, loss = 3.13922262\n",
            "Validation score: 0.002377\n",
            "Iteration 102, loss = 3.13919571\n",
            "Validation score: 0.002837\n",
            "Iteration 103, loss = 3.13875876\n",
            "Validation score: 0.003102\n",
            "Iteration 104, loss = 3.13924990\n",
            "Validation score: 0.002885\n",
            "Iteration 105, loss = 3.13822472\n",
            "Validation score: 0.002435\n",
            "Iteration 106, loss = 3.13784955\n",
            "Validation score: 0.003373\n",
            "Iteration 107, loss = 3.13774219\n",
            "Validation score: 0.003502\n",
            "Iteration 108, loss = 3.13722621\n",
            "Validation score: 0.003805\n",
            "Iteration 109, loss = 3.13632172\n",
            "Validation score: 0.003399\n",
            "Iteration 110, loss = 3.13712756\n",
            "Validation score: 0.003320\n",
            "Iteration 111, loss = 3.13656648\n",
            "Validation score: 0.004005\n",
            "Iteration 112, loss = 3.13564984\n",
            "Validation score: 0.004268\n",
            "Iteration 113, loss = 3.13497657\n",
            "Validation score: 0.004527\n",
            "Iteration 114, loss = 3.13426918\n",
            "Validation score: 0.002835\n",
            "Iteration 115, loss = 3.13389664\n",
            "Validation score: 0.004685\n",
            "Iteration 116, loss = 3.13456216\n",
            "Validation score: 0.005038\n",
            "Iteration 117, loss = 3.13139850\n",
            "Validation score: 0.005165\n",
            "Iteration 118, loss = 3.13179964\n",
            "Validation score: 0.005035\n",
            "Iteration 119, loss = 3.13302179\n",
            "Validation score: 0.005315\n",
            "Iteration 120, loss = 3.13123334\n",
            "Validation score: 0.005921\n",
            "Iteration 121, loss = 3.12992551\n",
            "Validation score: 0.005962\n",
            "Iteration 122, loss = 3.12865213\n",
            "Validation score: 0.005892\n",
            "Iteration 123, loss = 3.12747395\n",
            "Validation score: 0.006086\n",
            "Iteration 124, loss = 3.12842373\n",
            "Validation score: 0.004294\n",
            "Iteration 125, loss = 3.12680643\n",
            "Validation score: 0.006832\n",
            "Iteration 126, loss = 3.12622035\n",
            "Validation score: 0.007604\n",
            "Iteration 127, loss = 3.12527704\n",
            "Validation score: 0.007369\n",
            "Iteration 128, loss = 3.12349459\n",
            "Validation score: 0.006766\n",
            "Iteration 129, loss = 3.12328292\n",
            "Validation score: 0.008537\n",
            "Iteration 130, loss = 3.12294699\n",
            "Validation score: 0.008119\n",
            "Iteration 131, loss = 3.12172111\n",
            "Validation score: 0.008550\n",
            "Iteration 132, loss = 3.11848839\n",
            "Validation score: 0.009751\n",
            "Iteration 133, loss = 3.12102103\n",
            "Validation score: 0.009990\n",
            "Iteration 134, loss = 3.11648293\n",
            "Validation score: 0.010333\n",
            "Iteration 135, loss = 3.11555300\n",
            "Validation score: 0.010842\n",
            "Iteration 136, loss = 3.11114178\n",
            "Validation score: 0.006975\n",
            "Iteration 137, loss = 3.11479976\n",
            "Validation score: 0.011120\n",
            "Iteration 138, loss = 3.11139527\n",
            "Validation score: 0.011493\n",
            "Iteration 139, loss = 3.10900657\n",
            "Validation score: 0.012535\n",
            "Iteration 140, loss = 3.10825339\n",
            "Validation score: 0.013478\n",
            "Iteration 141, loss = 3.10637381\n",
            "Validation score: 0.012483\n",
            "Iteration 142, loss = 3.10538904\n",
            "Validation score: 0.014298\n",
            "Iteration 143, loss = 3.10254555\n",
            "Validation score: 0.015206\n",
            "Iteration 144, loss = 3.10351387\n",
            "Validation score: 0.015606\n",
            "Iteration 145, loss = 3.09883849\n",
            "Validation score: 0.016624\n",
            "Iteration 146, loss = 3.09570467\n",
            "Validation score: 0.016301\n",
            "Iteration 147, loss = 3.09388611\n",
            "Validation score: 0.018060\n",
            "Iteration 148, loss = 3.09310506\n",
            "Validation score: 0.018810\n",
            "Iteration 149, loss = 3.09109505\n",
            "Validation score: 0.019614\n",
            "Iteration 150, loss = 3.08933097\n",
            "Validation score: 0.019701\n",
            "Iteration 151, loss = 3.08641325\n",
            "Validation score: 0.017810\n",
            "Iteration 152, loss = 3.08447238\n",
            "Validation score: 0.021844\n",
            "Iteration 153, loss = 3.08009181\n",
            "Validation score: 0.020933\n",
            "Iteration 154, loss = 3.07679899\n",
            "Validation score: 0.023900\n",
            "Iteration 155, loss = 3.07570704\n",
            "Validation score: 0.020696\n",
            "Iteration 156, loss = 3.07235846\n",
            "Validation score: 0.023827\n",
            "Iteration 157, loss = 3.06849082\n",
            "Validation score: 0.023148\n",
            "Iteration 158, loss = 3.06697313\n",
            "Validation score: 0.028033\n",
            "Iteration 159, loss = 3.06148324\n",
            "Validation score: 0.029185\n",
            "Iteration 160, loss = 3.05998512\n",
            "Validation score: 0.028134\n",
            "Iteration 161, loss = 3.05573680\n",
            "Validation score: 0.031062\n",
            "Iteration 162, loss = 3.05351921\n",
            "Validation score: 0.031806\n",
            "Iteration 163, loss = 3.04872851\n",
            "Validation score: 0.033947\n",
            "Iteration 164, loss = 3.04398638\n",
            "Validation score: 0.034626\n",
            "Iteration 165, loss = 3.04033174\n",
            "Validation score: 0.036354\n",
            "Iteration 166, loss = 3.03458091\n",
            "Validation score: 0.036518\n",
            "Iteration 167, loss = 3.03452031\n",
            "Validation score: 0.039412\n",
            "Iteration 168, loss = 3.03021225\n",
            "Validation score: 0.039982\n",
            "Iteration 169, loss = 3.02472214\n",
            "Validation score: 0.042439\n",
            "Iteration 170, loss = 3.02158482\n",
            "Validation score: 0.043857\n",
            "Iteration 171, loss = 3.01447542\n",
            "Validation score: 0.045411\n",
            "Iteration 172, loss = 3.00592123\n",
            "Validation score: 0.045429\n",
            "Iteration 173, loss = 3.00308166\n",
            "Validation score: 0.045434\n",
            "Iteration 174, loss = 2.99948362\n",
            "Validation score: 0.050739\n",
            "Iteration 175, loss = 2.99098838\n",
            "Validation score: 0.049379\n",
            "Iteration 176, loss = 2.98492655\n",
            "Validation score: 0.038924\n",
            "Iteration 177, loss = 2.99111270\n",
            "Validation score: 0.054658\n",
            "Iteration 178, loss = 2.97431275\n",
            "Validation score: 0.054739\n",
            "Iteration 179, loss = 2.96859340\n",
            "Validation score: 0.059638\n",
            "Iteration 180, loss = 2.96577468\n",
            "Validation score: 0.061929\n",
            "Iteration 181, loss = 2.95714819\n",
            "Validation score: 0.063927\n",
            "Iteration 182, loss = 2.94930685\n",
            "Validation score: 0.067008\n",
            "Iteration 183, loss = 2.94279654\n",
            "Validation score: 0.069465\n",
            "Iteration 184, loss = 2.93451821\n",
            "Validation score: 0.069986\n",
            "Iteration 185, loss = 2.92704646\n",
            "Validation score: 0.074181\n",
            "Iteration 186, loss = 2.91696921\n",
            "Validation score: 0.075531\n",
            "Iteration 187, loss = 2.91500649\n",
            "Validation score: 0.077380\n",
            "Iteration 188, loss = 2.90803479\n",
            "Validation score: 0.081925\n",
            "Iteration 189, loss = 2.89488806\n",
            "Validation score: 0.084272\n",
            "Iteration 190, loss = 2.88623757\n",
            "Validation score: 0.084083\n",
            "Iteration 191, loss = 2.88275744\n",
            "Validation score: 0.090493\n",
            "Iteration 192, loss = 2.86892899\n",
            "Validation score: 0.092918\n",
            "Iteration 193, loss = 2.86197875\n",
            "Validation score: 0.096275\n",
            "Iteration 194, loss = 2.85745127\n",
            "Validation score: 0.098181\n",
            "Iteration 195, loss = 2.84307593\n",
            "Validation score: 0.095924\n",
            "Iteration 196, loss = 2.83275283\n",
            "Validation score: 0.105900\n",
            "Iteration 197, loss = 2.82600668\n",
            "Validation score: 0.108260\n",
            "Iteration 198, loss = 2.81669991\n",
            "Validation score: 0.108816\n",
            "Iteration 199, loss = 2.80172927\n",
            "Validation score: 0.115570\n",
            "Iteration 200, loss = 2.78870126\n",
            "Validation score: 0.118591\n",
            "Iteration 201, loss = 2.77747188\n",
            "Validation score: 0.122538\n",
            "Iteration 202, loss = 2.76685510\n",
            "Validation score: 0.121979\n",
            "Iteration 203, loss = 2.76451719\n",
            "Validation score: 0.129222\n",
            "Iteration 204, loss = 2.74932548\n",
            "Validation score: 0.133921\n",
            "Iteration 205, loss = 2.73249895\n",
            "Validation score: 0.137962\n",
            "Iteration 206, loss = 2.72067316\n",
            "Validation score: 0.142028\n",
            "Iteration 207, loss = 2.71501653\n",
            "Validation score: 0.141832\n",
            "Iteration 208, loss = 2.70187341\n",
            "Validation score: 0.149994\n",
            "Iteration 209, loss = 2.68607254\n",
            "Validation score: 0.141339\n",
            "Iteration 210, loss = 2.67768331\n",
            "Validation score: 0.154688\n",
            "Iteration 211, loss = 2.66942967\n",
            "Validation score: 0.160898\n",
            "Iteration 212, loss = 2.65048524\n",
            "Validation score: 0.166042\n",
            "Iteration 213, loss = 2.64566978\n",
            "Validation score: 0.170675\n",
            "Iteration 214, loss = 2.61945480\n",
            "Validation score: 0.174305\n",
            "Iteration 215, loss = 2.61259764\n",
            "Validation score: 0.172513\n",
            "Iteration 216, loss = 2.60166054\n",
            "Validation score: 0.182737\n",
            "Iteration 217, loss = 2.58525128\n",
            "Validation score: 0.186377\n",
            "Iteration 218, loss = 2.56473772\n",
            "Validation score: 0.192937\n",
            "Iteration 219, loss = 2.55338902\n",
            "Validation score: 0.197375\n",
            "Iteration 220, loss = 2.54523456\n",
            "Validation score: 0.202035\n",
            "Iteration 221, loss = 2.52348747\n",
            "Validation score: 0.198327\n",
            "Iteration 222, loss = 2.51727988\n",
            "Validation score: 0.206560\n",
            "Iteration 223, loss = 2.49456824\n",
            "Validation score: 0.216536\n",
            "Iteration 224, loss = 2.48562904\n",
            "Validation score: 0.213775\n",
            "Iteration 225, loss = 2.46557770\n",
            "Validation score: 0.226030\n",
            "Iteration 226, loss = 2.44825701\n",
            "Validation score: 0.228964\n",
            "Iteration 227, loss = 2.43818793\n",
            "Validation score: 0.235154\n",
            "Iteration 228, loss = 2.42266084\n",
            "Validation score: 0.240624\n",
            "Iteration 229, loss = 2.41685351\n",
            "Validation score: 0.244751\n",
            "Iteration 230, loss = 2.38989101\n",
            "Validation score: 0.245071\n",
            "Iteration 231, loss = 2.37733500\n",
            "Validation score: 0.254884\n",
            "Iteration 232, loss = 2.36615780\n",
            "Validation score: 0.248687\n",
            "Iteration 233, loss = 2.35173284\n",
            "Validation score: 0.261334\n",
            "Iteration 234, loss = 2.32965231\n",
            "Validation score: 0.270977\n",
            "Iteration 235, loss = 2.31496001\n",
            "Validation score: 0.276275\n",
            "Iteration 236, loss = 2.29794347\n",
            "Validation score: 0.279882\n",
            "Iteration 237, loss = 2.28358244\n",
            "Validation score: 0.265840\n",
            "Iteration 238, loss = 2.27351340\n",
            "Validation score: 0.287276\n",
            "Iteration 239, loss = 2.25379759\n",
            "Validation score: 0.293718\n",
            "Iteration 240, loss = 2.23807162\n",
            "Validation score: 0.301304\n",
            "Iteration 241, loss = 2.22087368\n",
            "Validation score: 0.305207\n",
            "Iteration 242, loss = 2.20554509\n",
            "Validation score: 0.310633\n",
            "Iteration 243, loss = 2.18496945\n",
            "Validation score: 0.315548\n",
            "Iteration 244, loss = 2.18059019\n",
            "Validation score: 0.319863\n",
            "Iteration 245, loss = 2.15998263\n",
            "Validation score: 0.327182\n",
            "Iteration 246, loss = 2.14060542\n",
            "Validation score: 0.331812\n",
            "Iteration 247, loss = 2.12443729\n",
            "Validation score: 0.335846\n",
            "Iteration 248, loss = 2.10810628\n",
            "Validation score: 0.334873\n",
            "Iteration 249, loss = 2.10212683\n",
            "Validation score: 0.346754\n",
            "Iteration 250, loss = 2.07845513\n",
            "Validation score: 0.349645\n",
            "Iteration 251, loss = 2.07757398\n",
            "Validation score: 0.355983\n",
            "Iteration 252, loss = 2.05320537\n",
            "Validation score: 0.350803\n",
            "Iteration 253, loss = 2.04006522\n",
            "Validation score: 0.366583\n",
            "Iteration 254, loss = 2.02587212\n",
            "Validation score: 0.370747\n",
            "Iteration 255, loss = 2.01701549\n",
            "Validation score: 0.372516\n",
            "Iteration 256, loss = 1.99756743\n",
            "Validation score: 0.379060\n",
            "Iteration 257, loss = 1.97792725\n",
            "Validation score: 0.379416\n",
            "Iteration 258, loss = 1.96315908\n",
            "Validation score: 0.389303\n",
            "Iteration 259, loss = 1.94762067\n",
            "Validation score: 0.394542\n",
            "Iteration 260, loss = 1.93955072\n",
            "Validation score: 0.397286\n",
            "Iteration 261, loss = 1.92317102\n",
            "Validation score: 0.403665\n",
            "Iteration 262, loss = 1.90635971\n",
            "Validation score: 0.407437\n",
            "Iteration 263, loss = 1.89263404\n",
            "Validation score: 0.412616\n",
            "Iteration 264, loss = 1.87899554\n",
            "Validation score: 0.416263\n",
            "Iteration 265, loss = 1.87027712\n",
            "Validation score: 0.420442\n",
            "Iteration 266, loss = 1.85334223\n",
            "Validation score: 0.421260\n",
            "Iteration 267, loss = 1.84232690\n",
            "Validation score: 0.427551\n",
            "Iteration 268, loss = 1.82755079\n",
            "Validation score: 0.430025\n",
            "Iteration 269, loss = 1.81423407\n",
            "Validation score: 0.436236\n",
            "Iteration 270, loss = 1.80217802\n",
            "Validation score: 0.440963\n",
            "Iteration 271, loss = 1.79151217\n",
            "Validation score: 0.444596\n",
            "Iteration 272, loss = 1.77780037\n",
            "Validation score: 0.450067\n",
            "Iteration 273, loss = 1.76598384\n",
            "Validation score: 0.452137\n",
            "Iteration 274, loss = 1.75293486\n",
            "Validation score: 0.456972\n",
            "Iteration 275, loss = 1.74404637\n",
            "Validation score: 0.461513\n",
            "Iteration 276, loss = 1.73337068\n",
            "Validation score: 0.463885\n",
            "Iteration 277, loss = 1.72168705\n",
            "Validation score: 0.468606\n",
            "Iteration 278, loss = 1.71093975\n",
            "Validation score: 0.471649\n",
            "Iteration 279, loss = 1.70065537\n",
            "Validation score: 0.475571\n",
            "Iteration 280, loss = 1.68932897\n",
            "Validation score: 0.477286\n",
            "Iteration 281, loss = 1.67776773\n",
            "Validation score: 0.480342\n",
            "Iteration 282, loss = 1.66697079\n",
            "Validation score: 0.485024\n",
            "Iteration 283, loss = 1.65965632\n",
            "Validation score: 0.486570\n",
            "Iteration 284, loss = 1.65026370\n",
            "Validation score: 0.490391\n",
            "Iteration 285, loss = 1.63979894\n",
            "Validation score: 0.493899\n",
            "Iteration 286, loss = 1.62991856\n",
            "Validation score: 0.496192\n",
            "Iteration 287, loss = 1.61806750\n",
            "Validation score: 0.500803\n",
            "Iteration 288, loss = 1.60959065\n",
            "Validation score: 0.501860\n",
            "Iteration 289, loss = 1.59967080\n",
            "Validation score: 0.505626\n",
            "Iteration 290, loss = 1.59580059\n",
            "Validation score: 0.504701\n",
            "Iteration 291, loss = 1.58470171\n",
            "Validation score: 0.511045\n",
            "Iteration 292, loss = 1.58811332\n",
            "Validation score: 0.513911\n",
            "Iteration 293, loss = 1.56962817\n",
            "Validation score: 0.514993\n",
            "Iteration 294, loss = 1.56878311\n",
            "Validation score: 0.517927\n",
            "Iteration 295, loss = 1.55490976\n",
            "Validation score: 0.521707\n",
            "Iteration 296, loss = 1.54717274\n",
            "Validation score: 0.520794\n",
            "Iteration 297, loss = 1.53836757\n",
            "Validation score: 0.524552\n",
            "Iteration 298, loss = 1.53355665\n",
            "Validation score: 0.527234\n",
            "Iteration 299, loss = 1.52585623\n",
            "Validation score: 0.530790\n",
            "Iteration 300, loss = 1.51880133\n",
            "Validation score: 0.532242\n",
            "Iteration 301, loss = 1.50982885\n",
            "Validation score: 0.535216\n",
            "Iteration 302, loss = 1.50480500\n",
            "Validation score: 0.536908\n",
            "Iteration 303, loss = 1.49695621\n",
            "Validation score: 0.539278\n",
            "Iteration 304, loss = 1.49155853\n",
            "Validation score: 0.540493\n",
            "Iteration 305, loss = 1.48507830\n",
            "Validation score: 0.543457\n",
            "Iteration 306, loss = 1.47831967\n",
            "Validation score: 0.545198\n",
            "Iteration 307, loss = 1.47326349\n",
            "Validation score: 0.546900\n",
            "Iteration 308, loss = 1.46837297\n",
            "Validation score: 0.549109\n",
            "Iteration 309, loss = 1.46129122\n",
            "Validation score: 0.549980\n",
            "Iteration 310, loss = 1.45741362\n",
            "Validation score: 0.552763\n",
            "Iteration 311, loss = 1.44974459\n",
            "Validation score: 0.553992\n",
            "Iteration 312, loss = 1.44292609\n",
            "Validation score: 0.556419\n",
            "Iteration 313, loss = 1.43812264\n",
            "Validation score: 0.558118\n",
            "Iteration 314, loss = 1.43217980\n",
            "Validation score: 0.559052\n",
            "Iteration 315, loss = 1.42619317\n",
            "Validation score: 0.561106\n",
            "Iteration 316, loss = 1.42100694\n",
            "Validation score: 0.562444\n",
            "Iteration 317, loss = 1.41627990\n",
            "Validation score: 0.561758\n",
            "Iteration 318, loss = 1.41203943\n",
            "Validation score: 0.565658\n",
            "Iteration 319, loss = 1.40539586\n",
            "Validation score: 0.567898\n",
            "Iteration 320, loss = 1.40013530\n",
            "Validation score: 0.569535\n",
            "Iteration 321, loss = 1.39385579\n",
            "Validation score: 0.571519\n",
            "Iteration 322, loss = 1.38931638\n",
            "Validation score: 0.573125\n",
            "Iteration 323, loss = 1.38512824\n",
            "Validation score: 0.573531\n",
            "Iteration 324, loss = 1.37941696\n",
            "Validation score: 0.575627\n",
            "Iteration 325, loss = 1.37293981\n",
            "Validation score: 0.576829\n",
            "Iteration 326, loss = 1.37064249\n",
            "Validation score: 0.579627\n",
            "Iteration 327, loss = 1.36662024\n",
            "Validation score: 0.580484\n",
            "Iteration 328, loss = 1.35768210\n",
            "Validation score: 0.582879\n",
            "Iteration 329, loss = 1.35098736\n",
            "Validation score: 0.584764\n",
            "Iteration 330, loss = 1.34621764\n",
            "Validation score: 0.585909\n",
            "Iteration 331, loss = 1.34248140\n",
            "Validation score: 0.587812\n",
            "Iteration 332, loss = 1.33661111\n",
            "Validation score: 0.588278\n",
            "Iteration 333, loss = 1.33247032\n",
            "Validation score: 0.591433\n",
            "Iteration 334, loss = 1.32325847\n",
            "Validation score: 0.592247\n",
            "Iteration 335, loss = 1.31982936\n",
            "Validation score: 0.594092\n",
            "Iteration 336, loss = 1.31475303\n",
            "Validation score: 0.596528\n",
            "Iteration 337, loss = 1.30678500\n",
            "Validation score: 0.598208\n",
            "Iteration 338, loss = 1.30093276\n",
            "Validation score: 0.598586\n",
            "Iteration 339, loss = 1.29856584\n",
            "Validation score: 0.601277\n",
            "Iteration 340, loss = 1.29174716\n",
            "Validation score: 0.602676\n",
            "Iteration 341, loss = 1.28593039\n",
            "Validation score: 0.604526\n",
            "Iteration 342, loss = 1.27870921\n",
            "Validation score: 0.607459\n",
            "Iteration 343, loss = 1.27168536\n",
            "Validation score: 0.609478\n",
            "Iteration 344, loss = 1.26630139\n",
            "Validation score: 0.610950\n",
            "Iteration 345, loss = 1.26054183\n",
            "Validation score: 0.611931\n",
            "Iteration 346, loss = 1.25595449\n",
            "Validation score: 0.614769\n",
            "Iteration 347, loss = 1.24880341\n",
            "Validation score: 0.617323\n",
            "Iteration 348, loss = 1.24357259\n",
            "Validation score: 0.618970\n",
            "Iteration 349, loss = 1.23536293\n",
            "Validation score: 0.620404\n",
            "Iteration 350, loss = 1.22795424\n",
            "Validation score: 0.622093\n",
            "Iteration 351, loss = 1.22366071\n",
            "Validation score: 0.625427\n",
            "Iteration 352, loss = 1.22066173\n",
            "Validation score: 0.626846\n",
            "Iteration 353, loss = 1.21138886\n",
            "Validation score: 0.629598\n",
            "Iteration 354, loss = 1.20792290\n",
            "Validation score: 0.629867\n",
            "Iteration 355, loss = 1.20237387\n",
            "Validation score: 0.633399\n",
            "Iteration 356, loss = 1.18823383\n",
            "Validation score: 0.634830\n",
            "Iteration 357, loss = 1.18172628\n",
            "Validation score: 0.637947\n",
            "Iteration 358, loss = 1.17659171\n",
            "Validation score: 0.640244\n",
            "Iteration 359, loss = 1.16745985\n",
            "Validation score: 0.641803\n",
            "Iteration 360, loss = 1.15705242\n",
            "Validation score: 0.643112\n",
            "Iteration 361, loss = 1.15134934\n",
            "Validation score: 0.644109\n",
            "Iteration 362, loss = 1.14645551\n",
            "Validation score: 0.648602\n",
            "Iteration 363, loss = 1.13712497\n",
            "Validation score: 0.651098\n",
            "Iteration 364, loss = 1.12693139\n",
            "Validation score: 0.653736\n",
            "Iteration 365, loss = 1.11912529\n",
            "Validation score: 0.656758\n",
            "Iteration 366, loss = 1.11322763\n",
            "Validation score: 0.652019\n",
            "Iteration 367, loss = 1.10371931\n",
            "Validation score: 0.662095\n",
            "Iteration 368, loss = 1.09444871\n",
            "Validation score: 0.663241\n",
            "Iteration 369, loss = 1.08953272\n",
            "Validation score: 0.666797\n",
            "Iteration 370, loss = 1.07718996\n",
            "Validation score: 0.669778\n",
            "Iteration 371, loss = 1.07170187\n",
            "Validation score: 0.672446\n",
            "Iteration 372, loss = 1.06167052\n",
            "Validation score: 0.674958\n",
            "Iteration 373, loss = 1.06234164\n",
            "Validation score: 0.674835\n",
            "Iteration 374, loss = 1.04468729\n",
            "Validation score: 0.680485\n",
            "Iteration 375, loss = 1.03508994\n",
            "Validation score: 0.682305\n",
            "Iteration 376, loss = 1.02858357\n",
            "Validation score: 0.685669\n",
            "Iteration 377, loss = 1.01921384\n",
            "Validation score: 0.687888\n",
            "Iteration 378, loss = 1.01009027\n",
            "Validation score: 0.688569\n",
            "Iteration 379, loss = 1.00427539\n",
            "Validation score: 0.688296\n",
            "Iteration 380, loss = 0.98768749\n",
            "Validation score: 0.696832\n",
            "Iteration 381, loss = 0.98697523\n",
            "Validation score: 0.699033\n",
            "Iteration 382, loss = 0.97662625\n",
            "Validation score: 0.702741\n",
            "Iteration 383, loss = 0.96481240\n",
            "Validation score: 0.705994\n",
            "Iteration 384, loss = 0.95112976\n",
            "Validation score: 0.704714\n",
            "Iteration 385, loss = 0.94511961\n",
            "Validation score: 0.711849\n",
            "Iteration 386, loss = 0.94122852\n",
            "Validation score: 0.709194\n",
            "Iteration 387, loss = 0.93135660\n",
            "Validation score: 0.716777\n",
            "Iteration 388, loss = 0.91325131\n",
            "Validation score: 0.720675\n",
            "Iteration 389, loss = 0.90648090\n",
            "Validation score: 0.721649\n",
            "Iteration 390, loss = 0.90264206\n",
            "Validation score: 0.726396\n",
            "Iteration 391, loss = 0.89148453\n",
            "Validation score: 0.726007\n",
            "Iteration 392, loss = 0.87699181\n",
            "Validation score: 0.732177\n",
            "Iteration 393, loss = 0.88027039\n",
            "Validation score: 0.728193\n",
            "Iteration 394, loss = 0.86044395\n",
            "Validation score: 0.737375\n",
            "Iteration 395, loss = 0.84854824\n",
            "Validation score: 0.738904\n",
            "Iteration 396, loss = 0.83779890\n",
            "Validation score: 0.743654\n",
            "Iteration 397, loss = 0.82760086\n",
            "Validation score: 0.745289\n",
            "Iteration 398, loss = 0.81604107\n",
            "Validation score: 0.749865\n",
            "Iteration 399, loss = 0.80713269\n",
            "Validation score: 0.753867\n",
            "Iteration 400, loss = 0.79939985\n",
            "Validation score: 0.756732\n",
            "Iteration 401, loss = 0.78511135\n",
            "Validation score: 0.759018\n",
            "Iteration 402, loss = 0.77944653\n",
            "Validation score: 0.763555\n",
            "Iteration 403, loss = 0.76866919\n",
            "Validation score: 0.764510\n",
            "Iteration 404, loss = 0.75270529\n",
            "Validation score: 0.769385\n",
            "Iteration 405, loss = 0.74978489\n",
            "Validation score: 0.772863\n",
            "Iteration 406, loss = 0.73535130\n",
            "Validation score: 0.776214\n",
            "Iteration 407, loss = 0.72729759\n",
            "Validation score: 0.777491\n",
            "Iteration 408, loss = 0.71568774\n",
            "Validation score: 0.782319\n",
            "Iteration 409, loss = 0.70301413\n",
            "Validation score: 0.785875\n",
            "Iteration 410, loss = 0.69070941\n",
            "Validation score: 0.785391\n",
            "Iteration 411, loss = 0.68269964\n",
            "Validation score: 0.791729\n",
            "Iteration 412, loss = 0.68303476\n",
            "Validation score: 0.795517\n",
            "Iteration 413, loss = 0.65864177\n",
            "Validation score: 0.796317\n",
            "Iteration 414, loss = 0.65206412\n",
            "Validation score: 0.801616\n",
            "Iteration 415, loss = 0.64131771\n",
            "Validation score: 0.804965\n",
            "Iteration 416, loss = 0.62711375\n",
            "Validation score: 0.807179\n",
            "Iteration 417, loss = 0.62050990\n",
            "Validation score: 0.811789\n",
            "Iteration 418, loss = 0.60765792\n",
            "Validation score: 0.814882\n",
            "Iteration 419, loss = 0.59841626\n",
            "Validation score: 0.814686\n",
            "Iteration 420, loss = 0.58608357\n",
            "Validation score: 0.821008\n",
            "Iteration 421, loss = 0.57625310\n",
            "Validation score: 0.824692\n",
            "Iteration 422, loss = 0.56591150\n",
            "Validation score: 0.825336\n",
            "Iteration 423, loss = 0.56219676\n",
            "Validation score: 0.830809\n",
            "Iteration 424, loss = 0.54611491\n",
            "Validation score: 0.830969\n",
            "Iteration 425, loss = 0.53728710\n",
            "Validation score: 0.835675\n",
            "Iteration 426, loss = 0.52497441\n",
            "Validation score: 0.840620\n",
            "Iteration 427, loss = 0.51398882\n",
            "Validation score: 0.842289\n",
            "Iteration 428, loss = 0.50316057\n",
            "Validation score: 0.846607\n",
            "Iteration 429, loss = 0.49393520\n",
            "Validation score: 0.849598\n",
            "Iteration 430, loss = 0.48151278\n",
            "Validation score: 0.853561\n",
            "Iteration 431, loss = 0.47289188\n",
            "Validation score: 0.856377\n",
            "Iteration 432, loss = 0.46152278\n",
            "Validation score: 0.859897\n",
            "Iteration 433, loss = 0.45155588\n",
            "Validation score: 0.860439\n",
            "Iteration 434, loss = 0.44330189\n",
            "Validation score: 0.864468\n",
            "Iteration 435, loss = 0.43247576\n",
            "Validation score: 0.865114\n",
            "Iteration 436, loss = 0.43770859\n",
            "Validation score: 0.869368\n",
            "Iteration 437, loss = 0.41293696\n",
            "Validation score: 0.872048\n",
            "Iteration 438, loss = 0.40181249\n",
            "Validation score: 0.878313\n",
            "Iteration 439, loss = 0.39374058\n",
            "Validation score: 0.880905\n",
            "Iteration 440, loss = 0.38458281\n",
            "Validation score: 0.882094\n",
            "Iteration 441, loss = 0.37652794\n",
            "Validation score: 0.886189\n",
            "Iteration 442, loss = 0.36426483\n",
            "Validation score: 0.889657\n",
            "Iteration 443, loss = 0.35508874\n",
            "Validation score: 0.892676\n",
            "Iteration 444, loss = 0.34389334\n",
            "Validation score: 0.895665\n",
            "Iteration 445, loss = 0.33633409\n",
            "Validation score: 0.897633\n",
            "Iteration 446, loss = 0.32744177\n",
            "Validation score: 0.900520\n",
            "Iteration 447, loss = 0.31804879\n",
            "Validation score: 0.902717\n",
            "Iteration 448, loss = 0.30950540\n",
            "Validation score: 0.905051\n",
            "Iteration 449, loss = 0.30143546\n",
            "Validation score: 0.907899\n",
            "Iteration 450, loss = 0.29271420\n",
            "Validation score: 0.910353\n",
            "Iteration 451, loss = 0.28415285\n",
            "Validation score: 0.914357\n",
            "Iteration 452, loss = 0.27488728\n",
            "Validation score: 0.916072\n",
            "Iteration 453, loss = 0.26627433\n",
            "Validation score: 0.919323\n",
            "Iteration 454, loss = 0.25907379\n",
            "Validation score: 0.920104\n",
            "Iteration 455, loss = 0.25261825\n",
            "Validation score: 0.924504\n",
            "Iteration 456, loss = 0.24340581\n",
            "Validation score: 0.926929\n",
            "Iteration 457, loss = 0.23588947\n",
            "Validation score: 0.928456\n",
            "Iteration 458, loss = 0.22774600\n",
            "Validation score: 0.931520\n",
            "Iteration 459, loss = 0.22146079\n",
            "Validation score: 0.934234\n",
            "Iteration 460, loss = 0.21266130\n",
            "Validation score: 0.935998\n",
            "Iteration 461, loss = 0.20804873\n",
            "Validation score: 0.938228\n",
            "Iteration 462, loss = 0.19683851\n",
            "Validation score: 0.940653\n",
            "Iteration 463, loss = 0.19185937\n",
            "Validation score: 0.942067\n",
            "Iteration 464, loss = 0.18505819\n",
            "Validation score: 0.944582\n",
            "Iteration 465, loss = 0.17826244\n",
            "Validation score: 0.946897\n",
            "Iteration 466, loss = 0.17359902\n",
            "Validation score: 0.948194\n",
            "Iteration 467, loss = 0.16662966\n",
            "Validation score: 0.949384\n",
            "Iteration 468, loss = 0.16077977\n",
            "Validation score: 0.951564\n",
            "Iteration 469, loss = 0.15218546\n",
            "Validation score: 0.953842\n",
            "Iteration 470, loss = 0.14655164\n",
            "Validation score: 0.956456\n",
            "Iteration 471, loss = 0.14232438\n",
            "Validation score: 0.956996\n",
            "Iteration 472, loss = 0.13561869\n",
            "Validation score: 0.959302\n",
            "Iteration 473, loss = 0.13138245\n",
            "Validation score: 0.961334\n",
            "Iteration 474, loss = 0.12431891\n",
            "Validation score: 0.963071\n",
            "Iteration 475, loss = 0.12285105\n",
            "Validation score: 0.961886\n",
            "Iteration 476, loss = 0.11617529\n",
            "Validation score: 0.966057\n",
            "Iteration 477, loss = 0.11667345\n",
            "Validation score: 0.965038\n",
            "Iteration 478, loss = 0.10757478\n",
            "Validation score: 0.967636\n",
            "Iteration 479, loss = 0.10042482\n",
            "Validation score: 0.969967\n",
            "Iteration 480, loss = 0.09856867\n",
            "Validation score: 0.969082\n",
            "Iteration 481, loss = 0.09466065\n",
            "Validation score: 0.972928\n",
            "Iteration 482, loss = 0.08807735\n",
            "Validation score: 0.974099\n",
            "Iteration 483, loss = 0.08467344\n",
            "Validation score: 0.971579\n",
            "Iteration 484, loss = 0.08244825\n",
            "Validation score: 0.976420\n",
            "Iteration 485, loss = 0.07739551\n",
            "Validation score: 0.976884\n",
            "Iteration 486, loss = 0.07371750\n",
            "Validation score: 0.978562\n",
            "Iteration 487, loss = 0.06991881\n",
            "Validation score: 0.979535\n",
            "Iteration 488, loss = 0.06818220\n",
            "Validation score: 0.978688\n",
            "Iteration 489, loss = 0.06594825\n",
            "Validation score: 0.981274\n",
            "Iteration 490, loss = 0.06103348\n",
            "Validation score: 0.982031\n",
            "Iteration 491, loss = 0.05855048\n",
            "Validation score: 0.982708\n",
            "Iteration 492, loss = 0.05690505\n",
            "Validation score: 0.984158\n",
            "Iteration 493, loss = 0.05285161\n",
            "Validation score: 0.984371\n",
            "Iteration 494, loss = 0.04994611\n",
            "Validation score: 0.985569\n",
            "Iteration 495, loss = 0.04807920\n",
            "Validation score: 0.986168\n",
            "Iteration 496, loss = 0.04550994\n",
            "Validation score: 0.987063\n",
            "Iteration 497, loss = 0.04395029\n",
            "Validation score: 0.987363\n",
            "Iteration 498, loss = 0.04252857\n",
            "Validation score: 0.987349\n",
            "Iteration 499, loss = 0.04039947\n",
            "Validation score: 0.988698\n",
            "Iteration 500, loss = 0.03800031\n",
            "Validation score: 0.989426\n",
            "Iteration 501, loss = 0.03574376\n",
            "Validation score: 0.989120\n",
            "Iteration 502, loss = 0.03403198\n",
            "Validation score: 0.990386\n",
            "Iteration 503, loss = 0.03245207\n",
            "Validation score: 0.990714\n",
            "Iteration 504, loss = 0.03116212\n",
            "Validation score: 0.991553\n",
            "Iteration 505, loss = 0.02946555\n",
            "Validation score: 0.991898\n",
            "Iteration 506, loss = 0.02885054\n",
            "Validation score: 0.992384\n",
            "Iteration 507, loss = 0.02723818\n",
            "Validation score: 0.992542\n",
            "Iteration 508, loss = 0.02740919\n",
            "Validation score: 0.993071\n",
            "Iteration 509, loss = 0.02502882\n",
            "Validation score: 0.992920\n",
            "Iteration 510, loss = 0.02426376\n",
            "Validation score: 0.993602\n",
            "Iteration 511, loss = 0.02279296\n",
            "Validation score: 0.994086\n",
            "Iteration 512, loss = 0.02185354\n",
            "Validation score: 0.994350\n",
            "Iteration 513, loss = 0.02137924\n",
            "Validation score: 0.993651\n",
            "Iteration 514, loss = 0.02110788\n",
            "Validation score: 0.994612\n",
            "Iteration 515, loss = 0.01967379\n",
            "Validation score: 0.994297\n",
            "Iteration 516, loss = 0.01934489\n",
            "Validation score: 0.994786\n",
            "Iteration 517, loss = 0.01838226\n",
            "Validation score: 0.995044\n",
            "Iteration 518, loss = 0.01748855\n",
            "Validation score: 0.995605\n",
            "Iteration 519, loss = 0.01652976\n",
            "Validation score: 0.995784\n",
            "Iteration 520, loss = 0.01644146\n",
            "Validation score: 0.995184\n",
            "Iteration 521, loss = 0.01591313\n",
            "Validation score: 0.995841\n",
            "Iteration 522, loss = 0.01593491\n",
            "Validation score: 0.996056\n",
            "Iteration 523, loss = 0.01500795\n",
            "Validation score: 0.996169\n",
            "Iteration 524, loss = 0.01534326\n",
            "Validation score: 0.995790\n",
            "Iteration 525, loss = 0.01466549\n",
            "Validation score: 0.996265\n",
            "Iteration 526, loss = 0.01451454\n",
            "Validation score: 0.996642\n",
            "Iteration 527, loss = 0.01354465\n",
            "Validation score: 0.996803\n",
            "Iteration 528, loss = 0.01356858\n",
            "Validation score: 0.996485\n",
            "Iteration 529, loss = 0.01361535\n",
            "Validation score: 0.996876\n",
            "Iteration 530, loss = 0.01351526\n",
            "Validation score: 0.996958\n",
            "Iteration 531, loss = 0.01353936\n",
            "Validation score: 0.996676\n",
            "Iteration 532, loss = 0.01352897\n",
            "Validation score: 0.997090\n",
            "Iteration 533, loss = 0.01302351\n",
            "Validation score: 0.996506\n",
            "Iteration 534, loss = 0.01259590\n",
            "Validation score: 0.997133\n",
            "Iteration 535, loss = 0.01237702\n",
            "Validation score: 0.996989\n",
            "Iteration 536, loss = 0.01296457\n",
            "Validation score: 0.997272\n",
            "Iteration 537, loss = 0.01256087\n",
            "Validation score: 0.997237\n",
            "Iteration 538, loss = 0.01230144\n",
            "Validation score: 0.997347\n",
            "Iteration 539, loss = 0.01198461\n",
            "Validation score: 0.997328\n",
            "Iteration 540, loss = 0.01202708\n",
            "Validation score: 0.997033\n",
            "Iteration 541, loss = 0.01232375\n",
            "Validation score: 0.996523\n",
            "Iteration 542, loss = 0.01212870\n",
            "Validation score: 0.996716\n",
            "Iteration 543, loss = 0.01303756\n",
            "Validation score: 0.997058\n",
            "Iteration 544, loss = 0.01247939\n",
            "Validation score: 0.997487\n",
            "Iteration 545, loss = 0.01172438\n",
            "Validation score: 0.997007\n",
            "Iteration 546, loss = 0.01201516\n",
            "Validation score: 0.997239\n",
            "Iteration 547, loss = 0.01240844\n",
            "Validation score: 0.996850\n",
            "Iteration 548, loss = 0.01163345\n",
            "Validation score: 0.997594\n",
            "Iteration 549, loss = 0.01131282\n",
            "Validation score: 0.997612\n",
            "Iteration 550, loss = 0.01106005\n",
            "Validation score: 0.997420\n",
            "Iteration 551, loss = 0.01138632\n",
            "Validation score: 0.997216\n",
            "Iteration 552, loss = 0.01174870\n",
            "Validation score: 0.997563\n",
            "Iteration 553, loss = 0.01154388\n",
            "Validation score: 0.997536\n",
            "Iteration 554, loss = 0.01166563\n",
            "Validation score: 0.997584\n",
            "Iteration 555, loss = 0.01126310\n",
            "Validation score: 0.997424\n",
            "Iteration 556, loss = 0.01141059\n",
            "Validation score: 0.997605\n",
            "Iteration 557, loss = 0.01140739\n",
            "Validation score: 0.997660\n",
            "Iteration 558, loss = 0.01150701\n",
            "Validation score: 0.997251\n",
            "Iteration 559, loss = 0.01169134\n",
            "Validation score: 0.997425\n",
            "Iteration 560, loss = 0.01140693\n",
            "Validation score: 0.997652\n",
            "Iteration 561, loss = 0.01111507\n",
            "Validation score: 0.997434\n",
            "Iteration 562, loss = 0.01136059\n",
            "Validation score: 0.997632\n",
            "Iteration 563, loss = 0.01180605\n",
            "Validation score: 0.997406\n",
            "Iteration 564, loss = 0.01169655\n",
            "Validation score: 0.997633\n",
            "Iteration 565, loss = 0.01097838\n",
            "Validation score: 0.997393\n",
            "Iteration 566, loss = 0.01152799\n",
            "Validation score: 0.996959\n",
            "Iteration 567, loss = 0.01118598\n",
            "Validation score: 0.997528\n",
            "Iteration 568, loss = 0.01115632\n",
            "Validation score: 0.997596\n",
            "Iteration 569, loss = 0.01204007\n",
            "Validation score: 0.997075\n",
            "Iteration 570, loss = 0.01128714\n",
            "Validation score: 0.997704\n",
            "Iteration 571, loss = 0.01170268\n",
            "Validation score: 0.997430\n",
            "Iteration 572, loss = 0.01227394\n",
            "Validation score: 0.997607\n",
            "Iteration 573, loss = 0.01135963\n",
            "Validation score: 0.996734\n",
            "Iteration 574, loss = 0.01186122\n",
            "Validation score: 0.997725\n",
            "Iteration 575, loss = 0.01131865\n",
            "Validation score: 0.997044\n",
            "Iteration 576, loss = 0.01138221\n",
            "Validation score: 0.997698\n",
            "Iteration 577, loss = 0.01221782\n",
            "Validation score: 0.997531\n",
            "Iteration 578, loss = 0.01314757\n",
            "Validation score: 0.997542\n",
            "Iteration 579, loss = 0.01126333\n",
            "Validation score: 0.997531\n",
            "Iteration 580, loss = 0.01115773\n",
            "Validation score: 0.997551\n",
            "Iteration 581, loss = 0.01143985\n",
            "Validation score: 0.997529\n",
            "Iteration 582, loss = 0.01115344\n",
            "Validation score: 0.997040\n",
            "Iteration 583, loss = 0.01256680\n",
            "Validation score: 0.997132\n",
            "Iteration 584, loss = 0.01102385\n",
            "Validation score: 0.997570\n",
            "Iteration 585, loss = 0.01122727\n",
            "Validation score: 0.997723\n",
            "Iteration 586, loss = 0.01156606\n",
            "Validation score: 0.997244\n",
            "Iteration 587, loss = 0.01148203\n",
            "Validation score: 0.997644\n",
            "Iteration 588, loss = 0.01187822\n",
            "Validation score: 0.997173\n",
            "Iteration 589, loss = 0.01128209\n",
            "Validation score: 0.997151\n",
            "Iteration 590, loss = 0.01232627\n",
            "Validation score: 0.997282\n",
            "Iteration 591, loss = 0.01146581\n",
            "Validation score: 0.997729\n",
            "Iteration 592, loss = 0.01140090\n",
            "Validation score: 0.997512\n",
            "Iteration 593, loss = 0.01134022\n",
            "Validation score: 0.997717\n",
            "Iteration 594, loss = 0.01231450\n",
            "Validation score: 0.997562\n",
            "Iteration 595, loss = 0.01136959\n",
            "Validation score: 0.997336\n",
            "Iteration 596, loss = 0.01179936\n",
            "Validation score: 0.997432\n",
            "Iteration 597, loss = 0.01166300\n",
            "Validation score: 0.997731\n",
            "Iteration 598, loss = 0.01222552\n",
            "Validation score: 0.996794\n",
            "Iteration 599, loss = 0.01159060\n",
            "Validation score: 0.997712\n",
            "Iteration 600, loss = 0.01125052\n",
            "Validation score: 0.997327\n",
            "Iteration 601, loss = 0.01226879\n",
            "Validation score: 0.997348\n",
            "Iteration 602, loss = 0.01138386\n",
            "Validation score: 0.997623\n",
            "Iteration 603, loss = 0.01109712\n",
            "Validation score: 0.997392\n",
            "Iteration 604, loss = 0.01240440\n",
            "Validation score: 0.997278\n",
            "Iteration 605, loss = 0.01202692\n",
            "Validation score: 0.997627\n",
            "Iteration 606, loss = 0.01198710\n",
            "Validation score: 0.997569\n",
            "Iteration 607, loss = 0.01151842\n",
            "Validation score: 0.997725\n",
            "Iteration 608, loss = 0.01113183\n",
            "Validation score: 0.997745\n",
            "Iteration 609, loss = 0.01157570\n",
            "Validation score: 0.997525\n",
            "Iteration 610, loss = 0.01175690\n",
            "Validation score: 0.995890\n",
            "Iteration 611, loss = 0.01237679\n",
            "Validation score: 0.997466\n",
            "Iteration 612, loss = 0.01113481\n",
            "Validation score: 0.997681\n",
            "Iteration 613, loss = 0.01109398\n",
            "Validation score: 0.997492\n",
            "Iteration 614, loss = 0.01153762\n",
            "Validation score: 0.997165\n",
            "Iteration 615, loss = 0.01146808\n",
            "Validation score: 0.997383\n",
            "Iteration 616, loss = 0.01207384\n",
            "Validation score: 0.997398\n",
            "Iteration 617, loss = 0.01201458\n",
            "Validation score: 0.997675\n",
            "Iteration 618, loss = 0.01154963\n",
            "Validation score: 0.997287\n",
            "Iteration 619, loss = 0.01150585\n",
            "Validation score: 0.997055\n",
            "Iteration 620, loss = 0.01163171\n",
            "Validation score: 0.997079\n",
            "Iteration 621, loss = 0.01139637\n",
            "Validation score: 0.997528\n",
            "Iteration 622, loss = 0.01170653\n",
            "Validation score: 0.997602\n",
            "Iteration 623, loss = 0.01139306\n",
            "Validation score: 0.997243\n",
            "Iteration 624, loss = 0.01153726\n",
            "Validation score: 0.997484\n",
            "Iteration 625, loss = 0.01131746\n",
            "Validation score: 0.997610\n",
            "Iteration 626, loss = 0.01112296\n",
            "Validation score: 0.997244\n",
            "Iteration 627, loss = 0.01174724\n",
            "Validation score: 0.997067\n",
            "Iteration 628, loss = 0.01157746\n",
            "Validation score: 0.997677\n",
            "Iteration 629, loss = 0.01223318\n",
            "Validation score: 0.997682\n",
            "Iteration 630, loss = 0.01160838\n",
            "Validation score: 0.997728\n",
            "Iteration 631, loss = 0.01124674\n",
            "Validation score: 0.997699\n",
            "Iteration 632, loss = 0.01145271\n",
            "Validation score: 0.997374\n",
            "Iteration 633, loss = 0.01155656\n",
            "Validation score: 0.997741\n",
            "Iteration 634, loss = 0.01123508\n",
            "Validation score: 0.997549\n",
            "Iteration 635, loss = 0.01137772\n",
            "Validation score: 0.997246\n",
            "Iteration 636, loss = 0.01149649\n",
            "Validation score: 0.996707\n",
            "Iteration 637, loss = 0.01160272\n",
            "Validation score: 0.997700\n",
            "Iteration 638, loss = 0.01117151\n",
            "Validation score: 0.997659\n",
            "Iteration 639, loss = 0.01161427\n",
            "Validation score: 0.997320\n",
            "Iteration 640, loss = 0.01147764\n",
            "Validation score: 0.997497\n",
            "Iteration 641, loss = 0.01146761\n",
            "Validation score: 0.997639\n",
            "Iteration 642, loss = 0.01127180\n",
            "Validation score: 0.997310\n",
            "Iteration 643, loss = 0.01267207\n",
            "Validation score: 0.997645\n",
            "Iteration 644, loss = 0.01221345\n",
            "Validation score: 0.997518\n",
            "Iteration 645, loss = 0.01123848\n",
            "Validation score: 0.997718\n",
            "Iteration 646, loss = 0.01105050\n",
            "Validation score: 0.997734\n",
            "Iteration 647, loss = 0.01118993\n",
            "Validation score: 0.997014\n",
            "Iteration 648, loss = 0.01170715\n",
            "Validation score: 0.997693\n",
            "Iteration 649, loss = 0.01167189\n",
            "Validation score: 0.997382\n",
            "Validation score did not improve more than tol=0.000100 for 100 consecutive epochs. Stopping.\n",
            "Regression score:  0.9976047334169653\n",
            "true: \n",
            "[[ 2.42096655 -1.74839731]\n",
            " [ 0.09683895 -1.90048993]\n",
            " [ 1.21909285 -4.2650459 ]\n",
            " [ 4.12630369 -1.02405652]]\n",
            "predicted:\n",
            "[[ 2.41454552 -1.79475824]\n",
            " [ 0.03185991 -2.01787684]\n",
            " [ 1.01402792 -4.31541281]\n",
            " [ 4.17653305 -1.01470654]]\n",
            "Regression score:  0.9976818979014228\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}