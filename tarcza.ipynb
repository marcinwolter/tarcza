{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnmvM2mzAF0xIpbUz/Er+E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwolter/tarcza/blob/main/tarcza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wjjaybRKmoDE"
      },
      "outputs": [],
      "source": [
        "# prompt: random points on a plane within the radius R\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "#from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "\n",
        "# speed of sound\n",
        "v_s = 34000 # cm/s\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def monte_carlo_circle(R, R_mic, time_error, num_points):\n",
        "    \"\"\"\n",
        "    Points within a circle of radius R using Monte Carlo simulation.\n",
        "\n",
        "    Args:\n",
        "        R: The radius of the circle.\n",
        "        num_points: The number of random points to generate.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "            - x, y of the true points\n",
        "            - four times measured (one is zero)\n",
        "            - rotation flag\n",
        "    \"\"\"\n",
        "    # microphone positions\n",
        "    xy_mic = np.array([[0, R_mic], [R_mic, 0], [0, -R_mic], [-R_mic,0]])\n",
        "    time = np.zeros((4))\n",
        "\n",
        "    out_true = np.zeros((num_points, 2))\n",
        "    out_measured = np.zeros((num_points, 4))\n",
        "    rot_flag = np.zeros((num_points))\n",
        "    inside_circle = 0\n",
        "\n",
        "    while inside_circle < num_points:\n",
        "        x = random.uniform(-R, R)\n",
        "        y = random.uniform(-R, R)\n",
        "        distance2 = x*x + y*y\n",
        "        if distance2 <= R*R:\n",
        "          for i in range(4):\n",
        "            time[i] = np.sqrt((xy_mic[i,0]-x)**2 + (xy_mic[i,1]-y)**2)/v_s\n",
        "            # introduce error\n",
        "            time[i] = max(0,time[i]+random.gauss(0,time_error))\n",
        "\n",
        "          i_min = np.argmin(time)\n",
        "\n",
        "          for k in range(4):\n",
        "            out_measured[inside_circle, k] = time[k]-time[i_min]\n",
        "          rot_flag[inside_circle] = i_min\n",
        "\n",
        "          out_true[inside_circle, 0] = x\n",
        "          out_true[inside_circle, 1] = y\n",
        "\n",
        "          inside_circle += 1\n",
        "          #print(f\"point: {x, y, inside_circle}\")\n",
        "\n",
        "\n",
        "\n",
        "    return out_true, out_measured, rot_flag\n",
        "\n"
      ],
      "metadata": {
        "id": "0zXw3yqCAOhG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neural network regression out_measured -> out_true\n",
        "def regression(out_measured, out_true):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(out_measured, out_true,\n",
        "                                                    random_state=1)\n",
        "\n",
        "    #see https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
        "    regr = MLPRegressor(hidden_layer_sizes=(30,30), activation='relu', solver='adam',\n",
        "                        alpha=0.0001, batch_size='auto', learning_rate='adaptive',\n",
        "                        learning_rate_init=0.001, random_state=33, tol=0.0001,\n",
        "                        verbose=True, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
        "                        early_stopping=True, validation_fraction=0.2, n_iter_no_change=100,\n",
        "                        max_iter = 10000)\n",
        "    regr.fit(X_train, y_train)\n",
        "\n",
        "    #print(regr.predict(X_test[:4]))\n",
        "    #print(y_test[:4])\n",
        "\n",
        "    print(\"Regression score: \",regr.score(X_test, y_test))\n",
        "    #print(\"Score: \",regr.score(X_train, y_train))\n",
        "\n",
        "    return regr\n"
      ],
      "metadata": {
        "id": "B0HixMWq70zC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "radius = 5.0  # Set the radius of the circle\n",
        "num_points = 10000  # Set the number of random points\n",
        "R_mic = 7.\n",
        "time_error = 0.000001 # 0.00001\n",
        "\n",
        "out_true, out_meas, rot_flag = monte_carlo_circle(radius, R_mic, time_error, num_points)\n",
        "#print(f\"true: {out_true[0:4]}\")\n",
        "print(f\"meas: {out_meas[0:4]}\")\n",
        "print(f\"rot: {rot_flag[0:4]}\")\n",
        "print(out_true.shape, out_meas.shape, rot_flag.shape)\n",
        "\n",
        "regr = regression(out_meas, out_true)\n",
        "\n",
        "\n",
        "# Plot the 'loss_curve_' protery on model to see how well we are learning over the iterations\n",
        "pd.DataFrame(regr.loss_curve_).plot()\n",
        "\n",
        "# save the model to disk\n",
        "#filename = 'regr_model.sav'\n",
        "#pickle.dump(regr, open(filename, 'wb'))\n",
        "\n",
        "# load the model from disk\n",
        "#regr = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "# Test regressor on the new data\n",
        "out_true, out_meas, rot_flag = monte_carlo_circle(radius, R_mic, time_error, num_points)\n",
        "predicted = regr.predict(out_meas)\n",
        "print(\"true: \")\n",
        "print(out_true[0:4])\n",
        "print(\"predicted:\")\n",
        "print(predicted[0:4])\n",
        "print(\"Regression score: \",regr.score(out_meas, out_true))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1DsU4BizxAdX",
        "outputId": "bd0ca0cd-225b-4e9d-a36b-37f8dc5717bf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meas: [[1.05629912e-04 0.00000000e+00 2.04240756e-05 1.16354737e-04]\n",
            " [8.79086736e-05 0.00000000e+00 2.18062494e-05 1.05127132e-04]\n",
            " [2.40152371e-04 1.40662550e-04 0.00000000e+00 1.65119038e-04]\n",
            " [0.00000000e+00 1.42521715e-04 2.22140621e-04 1.33574460e-04]]\n",
            "rot: [1. 1. 2. 0.]\n",
            "(10000, 2) (10000, 4) (10000,)\n",
            "Iteration 1, loss = 3.10709062\n",
            "Validation score: -0.001235\n",
            "Iteration 2, loss = 3.10563243\n",
            "Validation score: -0.000695\n",
            "Iteration 3, loss = 3.10494235\n",
            "Validation score: -0.000469\n",
            "Iteration 4, loss = 3.10489076\n",
            "Validation score: -0.000483\n",
            "Iteration 5, loss = 3.10472628\n",
            "Validation score: -0.000547\n",
            "Iteration 6, loss = 3.10493099\n",
            "Validation score: -0.000609\n",
            "Iteration 7, loss = 3.10499443\n",
            "Validation score: -0.000384\n",
            "Iteration 8, loss = 3.10497667\n",
            "Validation score: -0.000534\n",
            "Iteration 9, loss = 3.10506970\n",
            "Validation score: -0.000717\n",
            "Iteration 10, loss = 3.10657348\n",
            "Validation score: -0.000603\n",
            "Iteration 11, loss = 3.10485389\n",
            "Validation score: -0.000393\n",
            "Iteration 12, loss = 3.10463358\n",
            "Validation score: -0.000534\n",
            "Iteration 13, loss = 3.10519134\n",
            "Validation score: -0.000526\n",
            "Iteration 14, loss = 3.10478906\n",
            "Validation score: -0.000426\n",
            "Iteration 15, loss = 3.10536845\n",
            "Validation score: -0.000425\n",
            "Iteration 16, loss = 3.10595647\n",
            "Validation score: -0.000685\n",
            "Iteration 17, loss = 3.10431700\n",
            "Validation score: -0.000378\n",
            "Iteration 18, loss = 3.10473509\n",
            "Validation score: -0.000486\n",
            "Iteration 19, loss = 3.10444869\n",
            "Validation score: -0.000360\n",
            "Iteration 20, loss = 3.10461204\n",
            "Validation score: -0.000513\n",
            "Iteration 21, loss = 3.10475485\n",
            "Validation score: -0.000598\n",
            "Iteration 22, loss = 3.10490977\n",
            "Validation score: -0.000390\n",
            "Iteration 23, loss = 3.10512206\n",
            "Validation score: -0.000528\n",
            "Iteration 24, loss = 3.10473278\n",
            "Validation score: -0.000339\n",
            "Iteration 25, loss = 3.10472244\n",
            "Validation score: -0.000638\n",
            "Iteration 26, loss = 3.10431834\n",
            "Validation score: -0.000275\n",
            "Iteration 27, loss = 3.10508170\n",
            "Validation score: -0.000415\n",
            "Iteration 28, loss = 3.10477732\n",
            "Validation score: -0.000403\n",
            "Iteration 29, loss = 3.10456572\n",
            "Validation score: -0.000508\n",
            "Iteration 30, loss = 3.10478065\n",
            "Validation score: -0.000267\n",
            "Iteration 31, loss = 3.10480667\n",
            "Validation score: -0.000418\n",
            "Iteration 32, loss = 3.10439758\n",
            "Validation score: -0.000332\n",
            "Iteration 33, loss = 3.10458036\n",
            "Validation score: -0.000466\n",
            "Iteration 34, loss = 3.10465443\n",
            "Validation score: -0.000264\n",
            "Iteration 35, loss = 3.10463157\n",
            "Validation score: -0.000237\n",
            "Iteration 36, loss = 3.10491712\n",
            "Validation score: -0.000659\n",
            "Iteration 37, loss = 3.10449015\n",
            "Validation score: -0.000174\n",
            "Iteration 38, loss = 3.10446271\n",
            "Validation score: -0.000505\n",
            "Iteration 39, loss = 3.10423535\n",
            "Validation score: -0.000150\n",
            "Iteration 40, loss = 3.10403029\n",
            "Validation score: -0.000290\n",
            "Iteration 41, loss = 3.10499881\n",
            "Validation score: -0.000524\n",
            "Iteration 42, loss = 3.10503486\n",
            "Validation score: -0.000355\n",
            "Iteration 43, loss = 3.10439339\n",
            "Validation score: -0.000346\n",
            "Iteration 44, loss = 3.10392409\n",
            "Validation score: -0.000307\n",
            "Iteration 45, loss = 3.10510661\n",
            "Validation score: -0.000711\n",
            "Iteration 46, loss = 3.10429429\n",
            "Validation score: -0.000339\n",
            "Iteration 47, loss = 3.10445240\n",
            "Validation score: -0.000142\n",
            "Iteration 48, loss = 3.10369024\n",
            "Validation score: -0.000543\n",
            "Iteration 49, loss = 3.10518110\n",
            "Validation score: 0.000048\n",
            "Iteration 50, loss = 3.10518895\n",
            "Validation score: -0.000331\n",
            "Iteration 51, loss = 3.10408090\n",
            "Validation score: -0.000251\n",
            "Iteration 52, loss = 3.10383465\n",
            "Validation score: -0.000057\n",
            "Iteration 53, loss = 3.10431488\n",
            "Validation score: -0.000626\n",
            "Iteration 54, loss = 3.10381004\n",
            "Validation score: -0.000124\n",
            "Iteration 55, loss = 3.10396448\n",
            "Validation score: -0.000179\n",
            "Iteration 56, loss = 3.10399949\n",
            "Validation score: 0.000077\n",
            "Iteration 57, loss = 3.10418653\n",
            "Validation score: -0.000042\n",
            "Iteration 58, loss = 3.10423971\n",
            "Validation score: -0.000030\n",
            "Iteration 59, loss = 3.10412638\n",
            "Validation score: -0.000257\n",
            "Iteration 60, loss = 3.10380805\n",
            "Validation score: -0.000217\n",
            "Iteration 61, loss = 3.10448036\n",
            "Validation score: 0.000171\n",
            "Iteration 62, loss = 3.10335103\n",
            "Validation score: -0.000207\n",
            "Iteration 63, loss = 3.10394481\n",
            "Validation score: 0.000148\n",
            "Iteration 64, loss = 3.10356156\n",
            "Validation score: 0.000149\n",
            "Iteration 65, loss = 3.10346859\n",
            "Validation score: -0.000147\n",
            "Iteration 66, loss = 3.10317873\n",
            "Validation score: -0.000003\n",
            "Iteration 67, loss = 3.10399922\n",
            "Validation score: 0.000041\n",
            "Iteration 68, loss = 3.10333846\n",
            "Validation score: 0.000038\n",
            "Iteration 69, loss = 3.10310959\n",
            "Validation score: -0.000246\n",
            "Iteration 70, loss = 3.10304888\n",
            "Validation score: 0.000175\n",
            "Iteration 71, loss = 3.10298595\n",
            "Validation score: 0.000013\n",
            "Iteration 72, loss = 3.10314466\n",
            "Validation score: 0.000377\n",
            "Iteration 73, loss = 3.10341462\n",
            "Validation score: -0.000270\n",
            "Iteration 74, loss = 3.10313155\n",
            "Validation score: 0.000116\n",
            "Iteration 75, loss = 3.10276143\n",
            "Validation score: 0.000194\n",
            "Iteration 76, loss = 3.10263612\n",
            "Validation score: 0.000263\n",
            "Iteration 77, loss = 3.10234028\n",
            "Validation score: 0.000452\n",
            "Iteration 78, loss = 3.10271773\n",
            "Validation score: 0.000372\n",
            "Iteration 79, loss = 3.10252576\n",
            "Validation score: 0.000348\n",
            "Iteration 80, loss = 3.10319409\n",
            "Validation score: 0.000303\n",
            "Iteration 81, loss = 3.10339628\n",
            "Validation score: 0.000475\n",
            "Iteration 82, loss = 3.10230965\n",
            "Validation score: 0.000515\n",
            "Iteration 83, loss = 3.10199440\n",
            "Validation score: 0.000567\n",
            "Iteration 84, loss = 3.10219688\n",
            "Validation score: 0.000713\n",
            "Iteration 85, loss = 3.10178300\n",
            "Validation score: 0.000497\n",
            "Iteration 86, loss = 3.10185258\n",
            "Validation score: 0.000452\n",
            "Iteration 87, loss = 3.10199809\n",
            "Validation score: 0.000215\n",
            "Iteration 88, loss = 3.10165063\n",
            "Validation score: 0.000845\n",
            "Iteration 89, loss = 3.10115817\n",
            "Validation score: 0.000839\n",
            "Iteration 90, loss = 3.10128711\n",
            "Validation score: 0.000597\n",
            "Iteration 91, loss = 3.10126538\n",
            "Validation score: 0.001052\n",
            "Iteration 92, loss = 3.10156044\n",
            "Validation score: -0.000250\n",
            "Iteration 93, loss = 3.10178409\n",
            "Validation score: 0.000813\n",
            "Iteration 94, loss = 3.10123114\n",
            "Validation score: 0.001258\n",
            "Iteration 95, loss = 3.10026914\n",
            "Validation score: 0.000696\n",
            "Iteration 96, loss = 3.10087632\n",
            "Validation score: 0.001301\n",
            "Iteration 97, loss = 3.10013673\n",
            "Validation score: 0.001267\n",
            "Iteration 98, loss = 3.10049641\n",
            "Validation score: 0.001052\n",
            "Iteration 99, loss = 3.09972864\n",
            "Validation score: 0.001642\n",
            "Iteration 100, loss = 3.09917489\n",
            "Validation score: 0.000978\n",
            "Iteration 101, loss = 3.09934100\n",
            "Validation score: 0.001409\n",
            "Iteration 102, loss = 3.09989261\n",
            "Validation score: 0.001172\n",
            "Iteration 103, loss = 3.09818935\n",
            "Validation score: 0.001886\n",
            "Iteration 104, loss = 3.09849933\n",
            "Validation score: 0.001112\n",
            "Iteration 105, loss = 3.09762574\n",
            "Validation score: 0.002109\n",
            "Iteration 106, loss = 3.09775862\n",
            "Validation score: 0.001232\n",
            "Iteration 107, loss = 3.09722038\n",
            "Validation score: 0.002232\n",
            "Iteration 108, loss = 3.09733609\n",
            "Validation score: 0.001977\n",
            "Iteration 109, loss = 3.09811450\n",
            "Validation score: 0.001900\n",
            "Iteration 110, loss = 3.09622765\n",
            "Validation score: 0.002743\n",
            "Iteration 111, loss = 3.09747711\n",
            "Validation score: 0.002146\n",
            "Iteration 112, loss = 3.09602329\n",
            "Validation score: 0.002160\n",
            "Iteration 113, loss = 3.09544586\n",
            "Validation score: 0.002636\n",
            "Iteration 114, loss = 3.09466196\n",
            "Validation score: 0.003279\n",
            "Iteration 115, loss = 3.09495904\n",
            "Validation score: 0.000795\n",
            "Iteration 116, loss = 3.09326630\n",
            "Validation score: 0.002089\n",
            "Iteration 117, loss = 3.09634660\n",
            "Validation score: 0.003169\n",
            "Iteration 118, loss = 3.09323187\n",
            "Validation score: 0.003486\n",
            "Iteration 119, loss = 3.09201164\n",
            "Validation score: 0.003776\n",
            "Iteration 120, loss = 3.09490150\n",
            "Validation score: 0.004071\n",
            "Iteration 121, loss = 3.09189064\n",
            "Validation score: 0.003776\n",
            "Iteration 122, loss = 3.09198531\n",
            "Validation score: 0.004176\n",
            "Iteration 123, loss = 3.09059065\n",
            "Validation score: 0.004865\n",
            "Iteration 124, loss = 3.08982562\n",
            "Validation score: 0.004767\n",
            "Iteration 125, loss = 3.08910545\n",
            "Validation score: 0.005126\n",
            "Iteration 126, loss = 3.08953884\n",
            "Validation score: 0.004011\n",
            "Iteration 127, loss = 3.08730447\n",
            "Validation score: 0.005651\n",
            "Iteration 128, loss = 3.08726051\n",
            "Validation score: 0.005386\n",
            "Iteration 129, loss = 3.08588345\n",
            "Validation score: 0.006187\n",
            "Iteration 130, loss = 3.08448940\n",
            "Validation score: 0.006542\n",
            "Iteration 131, loss = 3.08534739\n",
            "Validation score: 0.006069\n",
            "Iteration 132, loss = 3.08640768\n",
            "Validation score: 0.005707\n",
            "Iteration 133, loss = 3.08183231\n",
            "Validation score: 0.007187\n",
            "Iteration 134, loss = 3.08085564\n",
            "Validation score: 0.007271\n",
            "Iteration 135, loss = 3.07893024\n",
            "Validation score: 0.008107\n",
            "Iteration 136, loss = 3.08128934\n",
            "Validation score: 0.008717\n",
            "Iteration 137, loss = 3.07728602\n",
            "Validation score: 0.008608\n",
            "Iteration 138, loss = 3.07621721\n",
            "Validation score: 0.007192\n",
            "Iteration 139, loss = 3.07672383\n",
            "Validation score: 0.009436\n",
            "Iteration 140, loss = 3.07356965\n",
            "Validation score: 0.008856\n",
            "Iteration 141, loss = 3.07191905\n",
            "Validation score: 0.011245\n",
            "Iteration 142, loss = 3.06987279\n",
            "Validation score: 0.011120\n",
            "Iteration 143, loss = 3.06961837\n",
            "Validation score: 0.012022\n",
            "Iteration 144, loss = 3.06609178\n",
            "Validation score: 0.012414\n",
            "Iteration 145, loss = 3.06593584\n",
            "Validation score: 0.011935\n",
            "Iteration 146, loss = 3.06116959\n",
            "Validation score: 0.014191\n",
            "Iteration 147, loss = 3.06589801\n",
            "Validation score: 0.014360\n",
            "Iteration 148, loss = 3.06024071\n",
            "Validation score: 0.014764\n",
            "Iteration 149, loss = 3.05706126\n",
            "Validation score: 0.015160\n",
            "Iteration 150, loss = 3.05313621\n",
            "Validation score: 0.015383\n",
            "Iteration 151, loss = 3.05369315\n",
            "Validation score: 0.017525\n",
            "Iteration 152, loss = 3.04882597\n",
            "Validation score: 0.019039\n",
            "Iteration 153, loss = 3.04569849\n",
            "Validation score: 0.019658\n",
            "Iteration 154, loss = 3.04545830\n",
            "Validation score: 0.020328\n",
            "Iteration 155, loss = 3.04032378\n",
            "Validation score: 0.019929\n",
            "Iteration 156, loss = 3.03843767\n",
            "Validation score: 0.022366\n",
            "Iteration 157, loss = 3.03474777\n",
            "Validation score: 0.023836\n",
            "Iteration 158, loss = 3.03132314\n",
            "Validation score: 0.024041\n",
            "Iteration 159, loss = 3.02922173\n",
            "Validation score: 0.020786\n",
            "Iteration 160, loss = 3.02871910\n",
            "Validation score: 0.026918\n",
            "Iteration 161, loss = 3.02568900\n",
            "Validation score: 0.028639\n",
            "Iteration 162, loss = 3.01704833\n",
            "Validation score: 0.029489\n",
            "Iteration 163, loss = 3.02140363\n",
            "Validation score: 0.029917\n",
            "Iteration 164, loss = 3.00674775\n",
            "Validation score: 0.030406\n",
            "Iteration 165, loss = 3.00415483\n",
            "Validation score: 0.033966\n",
            "Iteration 166, loss = 3.00009858\n",
            "Validation score: 0.035568\n",
            "Iteration 167, loss = 2.99484645\n",
            "Validation score: 0.037207\n",
            "Iteration 168, loss = 2.99042105\n",
            "Validation score: 0.038515\n",
            "Iteration 169, loss = 2.98504213\n",
            "Validation score: 0.040683\n",
            "Iteration 170, loss = 2.97891639\n",
            "Validation score: 0.042897\n",
            "Iteration 171, loss = 2.97907466\n",
            "Validation score: 0.044450\n",
            "Iteration 172, loss = 2.96619743\n",
            "Validation score: 0.046248\n",
            "Iteration 173, loss = 2.96207598\n",
            "Validation score: 0.047883\n",
            "Iteration 174, loss = 2.95628718\n",
            "Validation score: 0.049061\n",
            "Iteration 175, loss = 2.95243647\n",
            "Validation score: 0.052834\n",
            "Iteration 176, loss = 2.94466656\n",
            "Validation score: 0.054927\n",
            "Iteration 177, loss = 2.93635609\n",
            "Validation score: 0.057296\n",
            "Iteration 178, loss = 2.92877202\n",
            "Validation score: 0.059502\n",
            "Iteration 179, loss = 2.91955521\n",
            "Validation score: 0.059249\n",
            "Iteration 180, loss = 2.92108404\n",
            "Validation score: 0.064957\n",
            "Iteration 181, loss = 2.90691943\n",
            "Validation score: 0.067672\n",
            "Iteration 182, loss = 2.89582744\n",
            "Validation score: 0.070573\n",
            "Iteration 183, loss = 2.88577681\n",
            "Validation score: 0.070864\n",
            "Iteration 184, loss = 2.87832635\n",
            "Validation score: 0.075651\n",
            "Iteration 185, loss = 2.86969568\n",
            "Validation score: 0.079275\n",
            "Iteration 186, loss = 2.85979737\n",
            "Validation score: 0.082072\n",
            "Iteration 187, loss = 2.85518222\n",
            "Validation score: 0.085692\n",
            "Iteration 188, loss = 2.84095878\n",
            "Validation score: 0.089120\n",
            "Iteration 189, loss = 2.82860423\n",
            "Validation score: 0.090481\n",
            "Iteration 190, loss = 2.83086048\n",
            "Validation score: 0.092370\n",
            "Iteration 191, loss = 2.81088848\n",
            "Validation score: 0.099608\n",
            "Iteration 192, loss = 2.79948762\n",
            "Validation score: 0.102834\n",
            "Iteration 193, loss = 2.79489857\n",
            "Validation score: 0.101504\n",
            "Iteration 194, loss = 2.78341430\n",
            "Validation score: 0.105786\n",
            "Iteration 195, loss = 2.76977114\n",
            "Validation score: 0.113300\n",
            "Iteration 196, loss = 2.75906783\n",
            "Validation score: 0.118190\n",
            "Iteration 197, loss = 2.74575804\n",
            "Validation score: 0.120264\n",
            "Iteration 198, loss = 2.72710945\n",
            "Validation score: 0.125894\n",
            "Iteration 199, loss = 2.72201756\n",
            "Validation score: 0.126496\n",
            "Iteration 200, loss = 2.70534729\n",
            "Validation score: 0.131637\n",
            "Iteration 201, loss = 2.69839793\n",
            "Validation score: 0.137450\n",
            "Iteration 202, loss = 2.67697066\n",
            "Validation score: 0.141289\n",
            "Iteration 203, loss = 2.66563892\n",
            "Validation score: 0.143392\n",
            "Iteration 204, loss = 2.65331322\n",
            "Validation score: 0.149797\n",
            "Iteration 205, loss = 2.64271458\n",
            "Validation score: 0.147326\n",
            "Iteration 206, loss = 2.62988158\n",
            "Validation score: 0.159177\n",
            "Iteration 207, loss = 2.61117531\n",
            "Validation score: 0.165976\n",
            "Iteration 208, loss = 2.59618966\n",
            "Validation score: 0.170440\n",
            "Iteration 209, loss = 2.58584633\n",
            "Validation score: 0.170697\n",
            "Iteration 210, loss = 2.56840470\n",
            "Validation score: 0.178388\n",
            "Iteration 211, loss = 2.56337885\n",
            "Validation score: 0.184878\n",
            "Iteration 212, loss = 2.53440566\n",
            "Validation score: 0.185128\n",
            "Iteration 213, loss = 2.52895999\n",
            "Validation score: 0.187194\n",
            "Iteration 214, loss = 2.50444436\n",
            "Validation score: 0.199860\n",
            "Iteration 215, loss = 2.49162620\n",
            "Validation score: 0.202228\n",
            "Iteration 216, loss = 2.49301270\n",
            "Validation score: 0.205181\n",
            "Iteration 217, loss = 2.45839716\n",
            "Validation score: 0.214472\n",
            "Iteration 218, loss = 2.44577098\n",
            "Validation score: 0.219688\n",
            "Iteration 219, loss = 2.42648252\n",
            "Validation score: 0.225191\n",
            "Iteration 220, loss = 2.41168555\n",
            "Validation score: 0.229420\n",
            "Iteration 221, loss = 2.40423862\n",
            "Validation score: 0.235837\n",
            "Iteration 222, loss = 2.38292280\n",
            "Validation score: 0.239849\n",
            "Iteration 223, loss = 2.36844679\n",
            "Validation score: 0.245721\n",
            "Iteration 224, loss = 2.34740020\n",
            "Validation score: 0.251466\n",
            "Iteration 225, loss = 2.33191853\n",
            "Validation score: 0.245094\n",
            "Iteration 226, loss = 2.32069552\n",
            "Validation score: 0.261235\n",
            "Iteration 227, loss = 2.30574052\n",
            "Validation score: 0.260302\n",
            "Iteration 228, loss = 2.28517748\n",
            "Validation score: 0.272783\n",
            "Iteration 229, loss = 2.26872145\n",
            "Validation score: 0.277941\n",
            "Iteration 230, loss = 2.25593090\n",
            "Validation score: 0.280771\n",
            "Iteration 231, loss = 2.23514613\n",
            "Validation score: 0.284354\n",
            "Iteration 232, loss = 2.22557078\n",
            "Validation score: 0.290530\n",
            "Iteration 233, loss = 2.20848384\n",
            "Validation score: 0.294458\n",
            "Iteration 234, loss = 2.19383038\n",
            "Validation score: 0.304057\n",
            "Iteration 235, loss = 2.17216489\n",
            "Validation score: 0.305811\n",
            "Iteration 236, loss = 2.16220286\n",
            "Validation score: 0.311636\n",
            "Iteration 237, loss = 2.13801672\n",
            "Validation score: 0.317941\n",
            "Iteration 238, loss = 2.12371134\n",
            "Validation score: 0.324707\n",
            "Iteration 239, loss = 2.10879227\n",
            "Validation score: 0.330046\n",
            "Iteration 240, loss = 2.10165019\n",
            "Validation score: 0.332464\n",
            "Iteration 241, loss = 2.07704016\n",
            "Validation score: 0.339988\n",
            "Iteration 242, loss = 2.06367287\n",
            "Validation score: 0.336110\n",
            "Iteration 243, loss = 2.05356675\n",
            "Validation score: 0.347716\n",
            "Iteration 244, loss = 2.03923961\n",
            "Validation score: 0.349709\n",
            "Iteration 245, loss = 2.03087764\n",
            "Validation score: 0.357542\n",
            "Iteration 246, loss = 2.00271490\n",
            "Validation score: 0.359367\n",
            "Iteration 247, loss = 1.99554071\n",
            "Validation score: 0.364999\n",
            "Iteration 248, loss = 1.97858625\n",
            "Validation score: 0.372308\n",
            "Iteration 249, loss = 1.96562371\n",
            "Validation score: 0.376158\n",
            "Iteration 250, loss = 1.94964073\n",
            "Validation score: 0.381629\n",
            "Iteration 251, loss = 1.93436980\n",
            "Validation score: 0.377017\n",
            "Iteration 252, loss = 1.92347731\n",
            "Validation score: 0.390752\n",
            "Iteration 253, loss = 1.90916193\n",
            "Validation score: 0.394721\n",
            "Iteration 254, loss = 1.89481836\n",
            "Validation score: 0.397325\n",
            "Iteration 255, loss = 1.88861759\n",
            "Validation score: 0.400638\n",
            "Iteration 256, loss = 1.86965352\n",
            "Validation score: 0.407140\n",
            "Iteration 257, loss = 1.85801971\n",
            "Validation score: 0.410986\n",
            "Iteration 258, loss = 1.85100318\n",
            "Validation score: 0.414493\n",
            "Iteration 259, loss = 1.83747227\n",
            "Validation score: 0.408838\n",
            "Iteration 260, loss = 1.83474165\n",
            "Validation score: 0.412758\n",
            "Iteration 261, loss = 1.81873513\n",
            "Validation score: 0.425490\n",
            "Iteration 262, loss = 1.80101354\n",
            "Validation score: 0.428438\n",
            "Iteration 263, loss = 1.79323613\n",
            "Validation score: 0.430776\n",
            "Iteration 264, loss = 1.78065390\n",
            "Validation score: 0.435475\n",
            "Iteration 265, loss = 1.76994585\n",
            "Validation score: 0.438981\n",
            "Iteration 266, loss = 1.76051441\n",
            "Validation score: 0.440530\n",
            "Iteration 267, loss = 1.75162330\n",
            "Validation score: 0.444238\n",
            "Iteration 268, loss = 1.74229766\n",
            "Validation score: 0.447838\n",
            "Iteration 269, loss = 1.73388308\n",
            "Validation score: 0.450917\n",
            "Iteration 270, loss = 1.72820570\n",
            "Validation score: 0.452456\n",
            "Iteration 271, loss = 1.71673560\n",
            "Validation score: 0.456455\n",
            "Iteration 272, loss = 1.70727612\n",
            "Validation score: 0.456515\n",
            "Iteration 273, loss = 1.70608222\n",
            "Validation score: 0.455385\n",
            "Iteration 274, loss = 1.69444540\n",
            "Validation score: 0.462226\n",
            "Iteration 275, loss = 1.68654298\n",
            "Validation score: 0.465811\n",
            "Iteration 276, loss = 1.68072626\n",
            "Validation score: 0.467939\n",
            "Iteration 277, loss = 1.67243235\n",
            "Validation score: 0.469494\n",
            "Iteration 278, loss = 1.66495558\n",
            "Validation score: 0.472496\n",
            "Iteration 279, loss = 1.66124294\n",
            "Validation score: 0.473468\n",
            "Iteration 280, loss = 1.65727180\n",
            "Validation score: 0.473129\n",
            "Iteration 281, loss = 1.65143655\n",
            "Validation score: 0.476666\n",
            "Iteration 282, loss = 1.64399584\n",
            "Validation score: 0.479186\n",
            "Iteration 283, loss = 1.63891597\n",
            "Validation score: 0.481302\n",
            "Iteration 284, loss = 1.63276060\n",
            "Validation score: 0.483010\n",
            "Iteration 285, loss = 1.62879212\n",
            "Validation score: 0.483064\n",
            "Iteration 286, loss = 1.62482299\n",
            "Validation score: 0.485859\n",
            "Iteration 287, loss = 1.61994270\n",
            "Validation score: 0.487106\n",
            "Iteration 288, loss = 1.61648262\n",
            "Validation score: 0.488076\n",
            "Iteration 289, loss = 1.61264940\n",
            "Validation score: 0.488311\n",
            "Iteration 290, loss = 1.60973547\n",
            "Validation score: 0.489949\n",
            "Iteration 291, loss = 1.60747500\n",
            "Validation score: 0.491414\n",
            "Iteration 292, loss = 1.60180257\n",
            "Validation score: 0.492740\n",
            "Iteration 293, loss = 1.59992319\n",
            "Validation score: 0.493510\n",
            "Iteration 294, loss = 1.59590250\n",
            "Validation score: 0.494619\n",
            "Iteration 295, loss = 1.59342808\n",
            "Validation score: 0.495224\n",
            "Iteration 296, loss = 1.59188068\n",
            "Validation score: 0.494688\n",
            "Iteration 297, loss = 1.58983223\n",
            "Validation score: 0.496852\n",
            "Iteration 298, loss = 1.58675021\n",
            "Validation score: 0.497454\n",
            "Iteration 299, loss = 1.58457774\n",
            "Validation score: 0.497956\n",
            "Iteration 300, loss = 1.58345292\n",
            "Validation score: 0.497917\n",
            "Iteration 301, loss = 1.58146567\n",
            "Validation score: 0.499091\n",
            "Iteration 302, loss = 1.57978343\n",
            "Validation score: 0.499725\n",
            "Iteration 303, loss = 1.57891247\n",
            "Validation score: 0.498448\n",
            "Iteration 304, loss = 1.57786791\n",
            "Validation score: 0.499789\n",
            "Iteration 305, loss = 1.57798252\n",
            "Validation score: 0.500419\n",
            "Iteration 306, loss = 1.57540201\n",
            "Validation score: 0.501339\n",
            "Iteration 307, loss = 1.57311742\n",
            "Validation score: 0.501522\n",
            "Iteration 308, loss = 1.57269789\n",
            "Validation score: 0.501941\n",
            "Iteration 309, loss = 1.57150003\n",
            "Validation score: 0.502099\n",
            "Iteration 310, loss = 1.57060566\n",
            "Validation score: 0.502231\n",
            "Iteration 311, loss = 1.57020775\n",
            "Validation score: 0.502598\n",
            "Iteration 312, loss = 1.56924205\n",
            "Validation score: 0.502949\n",
            "Iteration 313, loss = 1.56853221\n",
            "Validation score: 0.502942\n",
            "Iteration 314, loss = 1.56858637\n",
            "Validation score: 0.503011\n",
            "Iteration 315, loss = 1.56768581\n",
            "Validation score: 0.503244\n",
            "Iteration 316, loss = 1.56715527\n",
            "Validation score: 0.503470\n",
            "Iteration 317, loss = 1.56687398\n",
            "Validation score: 0.503567\n",
            "Iteration 318, loss = 1.56706026\n",
            "Validation score: 0.503711\n",
            "Iteration 319, loss = 1.56583564\n",
            "Validation score: 0.503799\n",
            "Iteration 320, loss = 1.56556235\n",
            "Validation score: 0.503946\n",
            "Iteration 321, loss = 1.56587014\n",
            "Validation score: 0.503982\n",
            "Iteration 322, loss = 1.56526931\n",
            "Validation score: 0.504083\n",
            "Iteration 323, loss = 1.56481224\n",
            "Validation score: 0.504080\n",
            "Iteration 324, loss = 1.56455376\n",
            "Validation score: 0.503915\n",
            "Iteration 325, loss = 1.56445346\n",
            "Validation score: 0.503989\n",
            "Iteration 326, loss = 1.56461323\n",
            "Validation score: 0.504307\n",
            "Iteration 327, loss = 1.56444731\n",
            "Validation score: 0.504250\n",
            "Iteration 328, loss = 1.56433030\n",
            "Validation score: 0.504431\n",
            "Iteration 329, loss = 1.56384619\n",
            "Validation score: 0.504352\n",
            "Iteration 330, loss = 1.56377994\n",
            "Validation score: 0.504532\n",
            "Iteration 331, loss = 1.56417933\n",
            "Validation score: 0.504435\n",
            "Iteration 332, loss = 1.56363725\n",
            "Validation score: 0.504446\n",
            "Iteration 333, loss = 1.56351291\n",
            "Validation score: 0.504254\n",
            "Iteration 334, loss = 1.56398234\n",
            "Validation score: 0.504678\n",
            "Iteration 335, loss = 1.56366551\n",
            "Validation score: 0.504548\n",
            "Iteration 336, loss = 1.56328053\n",
            "Validation score: 0.504412\n",
            "Iteration 337, loss = 1.56339614\n",
            "Validation score: 0.504596\n",
            "Iteration 338, loss = 1.56304761\n",
            "Validation score: 0.504369\n",
            "Iteration 339, loss = 1.56374020\n",
            "Validation score: 0.504634\n",
            "Iteration 340, loss = 1.56307543\n",
            "Validation score: 0.504782\n",
            "Iteration 341, loss = 1.56303894\n",
            "Validation score: 0.504488\n",
            "Iteration 342, loss = 1.56314672\n",
            "Validation score: 0.504246\n",
            "Iteration 343, loss = 1.56303720\n",
            "Validation score: 0.504730\n",
            "Iteration 344, loss = 1.56310746\n",
            "Validation score: 0.504445\n",
            "Iteration 345, loss = 1.56305928\n",
            "Validation score: 0.504717\n",
            "Iteration 346, loss = 1.56308317\n",
            "Validation score: 0.504269\n",
            "Iteration 347, loss = 1.56293176\n",
            "Validation score: 0.504696\n",
            "Iteration 348, loss = 1.56307640\n",
            "Validation score: 0.504540\n",
            "Iteration 349, loss = 1.56289885\n",
            "Validation score: 0.504551\n",
            "Iteration 350, loss = 1.56307849\n",
            "Validation score: 0.504604\n",
            "Iteration 351, loss = 1.56282946\n",
            "Validation score: 0.504817\n",
            "Iteration 352, loss = 1.56265842\n",
            "Validation score: 0.504615\n",
            "Iteration 353, loss = 1.56324653\n",
            "Validation score: 0.504799\n",
            "Iteration 354, loss = 1.56310218\n",
            "Validation score: 0.504672\n",
            "Iteration 355, loss = 1.56273949\n",
            "Validation score: 0.504853\n",
            "Iteration 356, loss = 1.56267683\n",
            "Validation score: 0.504777\n",
            "Iteration 357, loss = 1.56236887\n",
            "Validation score: 0.504842\n",
            "Iteration 358, loss = 1.56341243\n",
            "Validation score: 0.504751\n",
            "Iteration 359, loss = 1.56265520\n",
            "Validation score: 0.504668\n",
            "Iteration 360, loss = 1.56251649\n",
            "Validation score: 0.504888\n",
            "Iteration 361, loss = 1.56307555\n",
            "Validation score: 0.504345\n",
            "Iteration 362, loss = 1.56263588\n",
            "Validation score: 0.504289\n",
            "Iteration 363, loss = 1.56265256\n",
            "Validation score: 0.504971\n",
            "Iteration 364, loss = 1.56248694\n",
            "Validation score: 0.504848\n",
            "Iteration 365, loss = 1.56229110\n",
            "Validation score: 0.504435\n",
            "Iteration 366, loss = 1.56216330\n",
            "Validation score: 0.504805\n",
            "Iteration 367, loss = 1.56375717\n",
            "Validation score: 0.504652\n",
            "Iteration 368, loss = 1.56226648\n",
            "Validation score: 0.504781\n",
            "Iteration 369, loss = 1.56213866\n",
            "Validation score: 0.504789\n",
            "Iteration 370, loss = 1.56213510\n",
            "Validation score: 0.505044\n",
            "Iteration 371, loss = 1.56197051\n",
            "Validation score: 0.504947\n",
            "Iteration 372, loss = 1.56241808\n",
            "Validation score: 0.504231\n",
            "Iteration 373, loss = 1.56268055\n",
            "Validation score: 0.504779\n",
            "Iteration 374, loss = 1.56278044\n",
            "Validation score: 0.504757\n",
            "Iteration 375, loss = 1.56206655\n",
            "Validation score: 0.504732\n",
            "Iteration 376, loss = 1.56208439\n",
            "Validation score: 0.505086\n",
            "Iteration 377, loss = 1.56217592\n",
            "Validation score: 0.504906\n",
            "Iteration 378, loss = 1.56186925\n",
            "Validation score: 0.504842\n",
            "Iteration 379, loss = 1.56176159\n",
            "Validation score: 0.505007\n",
            "Iteration 380, loss = 1.56147392\n",
            "Validation score: 0.505018\n",
            "Iteration 381, loss = 1.56164780\n",
            "Validation score: 0.505075\n",
            "Iteration 382, loss = 1.56134708\n",
            "Validation score: 0.505082\n",
            "Iteration 383, loss = 1.56164616\n",
            "Validation score: 0.504914\n",
            "Iteration 384, loss = 1.56201647\n",
            "Validation score: 0.505085\n",
            "Iteration 385, loss = 1.56204767\n",
            "Validation score: 0.504960\n",
            "Iteration 386, loss = 1.56148021\n",
            "Validation score: 0.504714\n",
            "Iteration 387, loss = 1.56130378\n",
            "Validation score: 0.505083\n",
            "Iteration 388, loss = 1.56202593\n",
            "Validation score: 0.505066\n",
            "Iteration 389, loss = 1.56116227\n",
            "Validation score: 0.505221\n",
            "Iteration 390, loss = 1.56111497\n",
            "Validation score: 0.504162\n",
            "Iteration 391, loss = 1.56281676\n",
            "Validation score: 0.504620\n",
            "Iteration 392, loss = 1.56124282\n",
            "Validation score: 0.505134\n",
            "Iteration 393, loss = 1.56102194\n",
            "Validation score: 0.505303\n",
            "Iteration 394, loss = 1.56069485\n",
            "Validation score: 0.505299\n",
            "Iteration 395, loss = 1.56072396\n",
            "Validation score: 0.505109\n",
            "Iteration 396, loss = 1.56084061\n",
            "Validation score: 0.505375\n",
            "Iteration 397, loss = 1.56056877\n",
            "Validation score: 0.505103\n",
            "Iteration 398, loss = 1.56074229\n",
            "Validation score: 0.505041\n",
            "Iteration 399, loss = 1.56080348\n",
            "Validation score: 0.505321\n",
            "Iteration 400, loss = 1.56083261\n",
            "Validation score: 0.505502\n",
            "Iteration 401, loss = 1.56049008\n",
            "Validation score: 0.505017\n",
            "Iteration 402, loss = 1.56090357\n",
            "Validation score: 0.505370\n",
            "Iteration 403, loss = 1.56044627\n",
            "Validation score: 0.505482\n",
            "Iteration 404, loss = 1.56033650\n",
            "Validation score: 0.505547\n",
            "Iteration 405, loss = 1.56046523\n",
            "Validation score: 0.505031\n",
            "Iteration 406, loss = 1.56040023\n",
            "Validation score: 0.505129\n",
            "Iteration 407, loss = 1.56058734\n",
            "Validation score: 0.505393\n",
            "Iteration 408, loss = 1.56043300\n",
            "Validation score: 0.505453\n",
            "Iteration 409, loss = 1.55958317\n",
            "Validation score: 0.505628\n",
            "Iteration 410, loss = 1.56010764\n",
            "Validation score: 0.505386\n",
            "Iteration 411, loss = 1.56043854\n",
            "Validation score: 0.505364\n",
            "Iteration 412, loss = 1.55979779\n",
            "Validation score: 0.505692\n",
            "Iteration 413, loss = 1.55970873\n",
            "Validation score: 0.505679\n",
            "Iteration 414, loss = 1.55973299\n",
            "Validation score: 0.505599\n",
            "Iteration 415, loss = 1.55976166\n",
            "Validation score: 0.505097\n",
            "Iteration 416, loss = 1.55992436\n",
            "Validation score: 0.505727\n",
            "Iteration 417, loss = 1.55905554\n",
            "Validation score: 0.505783\n",
            "Iteration 418, loss = 1.55896382\n",
            "Validation score: 0.505915\n",
            "Iteration 419, loss = 1.55903918\n",
            "Validation score: 0.505574\n",
            "Iteration 420, loss = 1.55903921\n",
            "Validation score: 0.505181\n",
            "Iteration 421, loss = 1.55932824\n",
            "Validation score: 0.505962\n",
            "Iteration 422, loss = 1.55839196\n",
            "Validation score: 0.505890\n",
            "Iteration 423, loss = 1.55843908\n",
            "Validation score: 0.505711\n",
            "Iteration 424, loss = 1.55890476\n",
            "Validation score: 0.505564\n",
            "Iteration 425, loss = 1.55930497\n",
            "Validation score: 0.505660\n",
            "Iteration 426, loss = 1.55839699\n",
            "Validation score: 0.505742\n",
            "Iteration 427, loss = 1.55835241\n",
            "Validation score: 0.505585\n",
            "Iteration 428, loss = 1.55860511\n",
            "Validation score: 0.505835\n",
            "Iteration 429, loss = 1.55820283\n",
            "Validation score: 0.506202\n",
            "Iteration 430, loss = 1.55820528\n",
            "Validation score: 0.506420\n",
            "Iteration 431, loss = 1.55719992\n",
            "Validation score: 0.506186\n",
            "Iteration 432, loss = 1.55775962\n",
            "Validation score: 0.506058\n",
            "Iteration 433, loss = 1.55762362\n",
            "Validation score: 0.505940\n",
            "Iteration 434, loss = 1.55770708\n",
            "Validation score: 0.506291\n",
            "Iteration 435, loss = 1.55732923\n",
            "Validation score: 0.506384\n",
            "Iteration 436, loss = 1.55740053\n",
            "Validation score: 0.506215\n",
            "Iteration 437, loss = 1.55680673\n",
            "Validation score: 0.506531\n",
            "Iteration 438, loss = 1.55658620\n",
            "Validation score: 0.506639\n",
            "Iteration 439, loss = 1.55678291\n",
            "Validation score: 0.506548\n",
            "Iteration 440, loss = 1.55647156\n",
            "Validation score: 0.506570\n",
            "Iteration 441, loss = 1.55713563\n",
            "Validation score: 0.506475\n",
            "Iteration 442, loss = 1.55738343\n",
            "Validation score: 0.506788\n",
            "Iteration 443, loss = 1.55631422\n",
            "Validation score: 0.506812\n",
            "Iteration 444, loss = 1.55669713\n",
            "Validation score: 0.505880\n",
            "Iteration 445, loss = 1.55619743\n",
            "Validation score: 0.506867\n",
            "Iteration 446, loss = 1.55516036\n",
            "Validation score: 0.506961\n",
            "Iteration 447, loss = 1.55574603\n",
            "Validation score: 0.506844\n",
            "Iteration 448, loss = 1.55681267\n",
            "Validation score: 0.506630\n",
            "Iteration 449, loss = 1.55481329\n",
            "Validation score: 0.506787\n",
            "Iteration 450, loss = 1.55545602\n",
            "Validation score: 0.506811\n",
            "Iteration 451, loss = 1.55436338\n",
            "Validation score: 0.506976\n",
            "Iteration 452, loss = 1.55436359\n",
            "Validation score: 0.507094\n",
            "Iteration 453, loss = 1.55460969\n",
            "Validation score: 0.507258\n",
            "Iteration 454, loss = 1.55416762\n",
            "Validation score: 0.507326\n",
            "Iteration 455, loss = 1.55427075\n",
            "Validation score: 0.507054\n",
            "Iteration 456, loss = 1.55377449\n",
            "Validation score: 0.507426\n",
            "Iteration 457, loss = 1.55368168\n",
            "Validation score: 0.507717\n",
            "Iteration 458, loss = 1.55341188\n",
            "Validation score: 0.507410\n",
            "Iteration 459, loss = 1.55324449\n",
            "Validation score: 0.507845\n",
            "Iteration 460, loss = 1.55243204\n",
            "Validation score: 0.507793\n",
            "Iteration 461, loss = 1.55282159\n",
            "Validation score: 0.507536\n",
            "Iteration 462, loss = 1.55342818\n",
            "Validation score: 0.506917\n",
            "Iteration 463, loss = 1.55276673\n",
            "Validation score: 0.507580\n",
            "Iteration 464, loss = 1.55224975\n",
            "Validation score: 0.508134\n",
            "Iteration 465, loss = 1.55225472\n",
            "Validation score: 0.508235\n",
            "Iteration 466, loss = 1.55179632\n",
            "Validation score: 0.508032\n",
            "Iteration 467, loss = 1.55176377\n",
            "Validation score: 0.508272\n",
            "Iteration 468, loss = 1.55064836\n",
            "Validation score: 0.508336\n",
            "Iteration 469, loss = 1.55038840\n",
            "Validation score: 0.508421\n",
            "Iteration 470, loss = 1.55036067\n",
            "Validation score: 0.508397\n",
            "Iteration 471, loss = 1.55076236\n",
            "Validation score: 0.508059\n",
            "Iteration 472, loss = 1.55038594\n",
            "Validation score: 0.508715\n",
            "Iteration 473, loss = 1.54980974\n",
            "Validation score: 0.508875\n",
            "Iteration 474, loss = 1.54978546\n",
            "Validation score: 0.509126\n",
            "Iteration 475, loss = 1.54924467\n",
            "Validation score: 0.509015\n",
            "Iteration 476, loss = 1.54889594\n",
            "Validation score: 0.507749\n",
            "Iteration 477, loss = 1.54937493\n",
            "Validation score: 0.508662\n",
            "Iteration 478, loss = 1.54890332\n",
            "Validation score: 0.509293\n",
            "Iteration 479, loss = 1.54958563\n",
            "Validation score: 0.509299\n",
            "Iteration 480, loss = 1.54781797\n",
            "Validation score: 0.509387\n",
            "Iteration 481, loss = 1.54729022\n",
            "Validation score: 0.509752\n",
            "Iteration 482, loss = 1.54681653\n",
            "Validation score: 0.509579\n",
            "Iteration 483, loss = 1.54619827\n",
            "Validation score: 0.509905\n",
            "Iteration 484, loss = 1.54574933\n",
            "Validation score: 0.509538\n",
            "Iteration 485, loss = 1.54547980\n",
            "Validation score: 0.509998\n",
            "Iteration 486, loss = 1.54550178\n",
            "Validation score: 0.510023\n",
            "Iteration 487, loss = 1.54533410\n",
            "Validation score: 0.510179\n",
            "Iteration 488, loss = 1.54460747\n",
            "Validation score: 0.510517\n",
            "Iteration 489, loss = 1.54384348\n",
            "Validation score: 0.510657\n",
            "Iteration 490, loss = 1.54408963\n",
            "Validation score: 0.510465\n",
            "Iteration 491, loss = 1.54329683\n",
            "Validation score: 0.510718\n",
            "Iteration 492, loss = 1.54266358\n",
            "Validation score: 0.511004\n",
            "Iteration 493, loss = 1.54256867\n",
            "Validation score: 0.510871\n",
            "Iteration 494, loss = 1.54226046\n",
            "Validation score: 0.511326\n",
            "Iteration 495, loss = 1.54142375\n",
            "Validation score: 0.511662\n",
            "Iteration 496, loss = 1.54182244\n",
            "Validation score: 0.511727\n",
            "Iteration 497, loss = 1.54081515\n",
            "Validation score: 0.511491\n",
            "Iteration 498, loss = 1.54028729\n",
            "Validation score: 0.510997\n",
            "Iteration 499, loss = 1.54070139\n",
            "Validation score: 0.511924\n",
            "Iteration 500, loss = 1.53923181\n",
            "Validation score: 0.511294\n",
            "Iteration 501, loss = 1.53899331\n",
            "Validation score: 0.511852\n",
            "Iteration 502, loss = 1.53830059\n",
            "Validation score: 0.512526\n",
            "Iteration 503, loss = 1.53715877\n",
            "Validation score: 0.512884\n",
            "Iteration 504, loss = 1.53686629\n",
            "Validation score: 0.512979\n",
            "Iteration 505, loss = 1.53597628\n",
            "Validation score: 0.513340\n",
            "Iteration 506, loss = 1.53526523\n",
            "Validation score: 0.513039\n",
            "Iteration 507, loss = 1.53547405\n",
            "Validation score: 0.512721\n",
            "Iteration 508, loss = 1.53404238\n",
            "Validation score: 0.514000\n",
            "Iteration 509, loss = 1.53520499\n",
            "Validation score: 0.513581\n",
            "Iteration 510, loss = 1.53264746\n",
            "Validation score: 0.514377\n",
            "Iteration 511, loss = 1.53292664\n",
            "Validation score: 0.514507\n",
            "Iteration 512, loss = 1.53123357\n",
            "Validation score: 0.514566\n",
            "Iteration 513, loss = 1.53082626\n",
            "Validation score: 0.514391\n",
            "Iteration 514, loss = 1.53140348\n",
            "Validation score: 0.515022\n",
            "Iteration 515, loss = 1.52961421\n",
            "Validation score: 0.515173\n",
            "Iteration 516, loss = 1.52867999\n",
            "Validation score: 0.515408\n",
            "Iteration 517, loss = 1.52794199\n",
            "Validation score: 0.515826\n",
            "Iteration 518, loss = 1.52725271\n",
            "Validation score: 0.515576\n",
            "Iteration 519, loss = 1.52615086\n",
            "Validation score: 0.515958\n",
            "Iteration 520, loss = 1.52561239\n",
            "Validation score: 0.516547\n",
            "Iteration 521, loss = 1.52495151\n",
            "Validation score: 0.516994\n",
            "Iteration 522, loss = 1.52404969\n",
            "Validation score: 0.516433\n",
            "Iteration 523, loss = 1.52259776\n",
            "Validation score: 0.516749\n",
            "Iteration 524, loss = 1.52249821\n",
            "Validation score: 0.517324\n",
            "Iteration 525, loss = 1.52098332\n",
            "Validation score: 0.518117\n",
            "Iteration 526, loss = 1.52121027\n",
            "Validation score: 0.518317\n",
            "Iteration 527, loss = 1.51991097\n",
            "Validation score: 0.517868\n",
            "Iteration 528, loss = 1.51854552\n",
            "Validation score: 0.519189\n",
            "Iteration 529, loss = 1.51745978\n",
            "Validation score: 0.518411\n",
            "Iteration 530, loss = 1.51678135\n",
            "Validation score: 0.519758\n",
            "Iteration 531, loss = 1.51401148\n",
            "Validation score: 0.518893\n",
            "Iteration 532, loss = 1.51311098\n",
            "Validation score: 0.520756\n",
            "Iteration 533, loss = 1.51201363\n",
            "Validation score: 0.520103\n",
            "Iteration 534, loss = 1.51133073\n",
            "Validation score: 0.521041\n",
            "Iteration 535, loss = 1.50936269\n",
            "Validation score: 0.521426\n",
            "Iteration 536, loss = 1.50956077\n",
            "Validation score: 0.521699\n",
            "Iteration 537, loss = 1.50990530\n",
            "Validation score: 0.522459\n",
            "Iteration 538, loss = 1.50615444\n",
            "Validation score: 0.522943\n",
            "Iteration 539, loss = 1.50431325\n",
            "Validation score: 0.523366\n",
            "Iteration 540, loss = 1.50247077\n",
            "Validation score: 0.523362\n",
            "Iteration 541, loss = 1.50232551\n",
            "Validation score: 0.524164\n",
            "Iteration 542, loss = 1.49949090\n",
            "Validation score: 0.525032\n",
            "Iteration 543, loss = 1.49903279\n",
            "Validation score: 0.524983\n",
            "Iteration 544, loss = 1.49621380\n",
            "Validation score: 0.525125\n",
            "Iteration 545, loss = 1.50029370\n",
            "Validation score: 0.525922\n",
            "Iteration 546, loss = 1.49365752\n",
            "Validation score: 0.525823\n",
            "Iteration 547, loss = 1.49300512\n",
            "Validation score: 0.524046\n",
            "Iteration 548, loss = 1.48972849\n",
            "Validation score: 0.528072\n",
            "Iteration 549, loss = 1.48951707\n",
            "Validation score: 0.527739\n",
            "Iteration 550, loss = 1.48642492\n",
            "Validation score: 0.527787\n",
            "Iteration 551, loss = 1.48747516\n",
            "Validation score: 0.525748\n",
            "Iteration 552, loss = 1.48293106\n",
            "Validation score: 0.529969\n",
            "Iteration 553, loss = 1.48335502\n",
            "Validation score: 0.530574\n",
            "Iteration 554, loss = 1.48095401\n",
            "Validation score: 0.531018\n",
            "Iteration 555, loss = 1.47767018\n",
            "Validation score: 0.531961\n",
            "Iteration 556, loss = 1.47565782\n",
            "Validation score: 0.532937\n",
            "Iteration 557, loss = 1.47279508\n",
            "Validation score: 0.533644\n",
            "Iteration 558, loss = 1.47360405\n",
            "Validation score: 0.534473\n",
            "Iteration 559, loss = 1.47018131\n",
            "Validation score: 0.531406\n",
            "Iteration 560, loss = 1.46693310\n",
            "Validation score: 0.535454\n",
            "Iteration 561, loss = 1.46361302\n",
            "Validation score: 0.536005\n",
            "Iteration 562, loss = 1.46109796\n",
            "Validation score: 0.537405\n",
            "Iteration 563, loss = 1.45974586\n",
            "Validation score: 0.538124\n",
            "Iteration 564, loss = 1.45704019\n",
            "Validation score: 0.538740\n",
            "Iteration 565, loss = 1.45818670\n",
            "Validation score: 0.538377\n",
            "Iteration 566, loss = 1.45096220\n",
            "Validation score: 0.539848\n",
            "Iteration 567, loss = 1.44919701\n",
            "Validation score: 0.540299\n",
            "Iteration 568, loss = 1.44523728\n",
            "Validation score: 0.541121\n",
            "Iteration 569, loss = 1.44320661\n",
            "Validation score: 0.543469\n",
            "Iteration 570, loss = 1.43897723\n",
            "Validation score: 0.544535\n",
            "Iteration 571, loss = 1.43674971\n",
            "Validation score: 0.545181\n",
            "Iteration 572, loss = 1.43628411\n",
            "Validation score: 0.545770\n",
            "Iteration 573, loss = 1.42979350\n",
            "Validation score: 0.547286\n",
            "Iteration 574, loss = 1.42732459\n",
            "Validation score: 0.546499\n",
            "Iteration 575, loss = 1.42792778\n",
            "Validation score: 0.549764\n",
            "Iteration 576, loss = 1.42056382\n",
            "Validation score: 0.550720\n",
            "Iteration 577, loss = 1.41705430\n",
            "Validation score: 0.551819\n",
            "Iteration 578, loss = 1.41409235\n",
            "Validation score: 0.552900\n",
            "Iteration 579, loss = 1.41128505\n",
            "Validation score: 0.552949\n",
            "Iteration 580, loss = 1.40653683\n",
            "Validation score: 0.555118\n",
            "Iteration 581, loss = 1.40241585\n",
            "Validation score: 0.553773\n",
            "Iteration 582, loss = 1.39858684\n",
            "Validation score: 0.557379\n",
            "Iteration 583, loss = 1.39388251\n",
            "Validation score: 0.559181\n",
            "Iteration 584, loss = 1.39084483\n",
            "Validation score: 0.560572\n",
            "Iteration 585, loss = 1.38678588\n",
            "Validation score: 0.560621\n",
            "Iteration 586, loss = 1.38348117\n",
            "Validation score: 0.558317\n",
            "Iteration 587, loss = 1.37787719\n",
            "Validation score: 0.563383\n",
            "Iteration 588, loss = 1.37216599\n",
            "Validation score: 0.565980\n",
            "Iteration 589, loss = 1.36827103\n",
            "Validation score: 0.566770\n",
            "Iteration 590, loss = 1.36498062\n",
            "Validation score: 0.568243\n",
            "Iteration 591, loss = 1.35792065\n",
            "Validation score: 0.570957\n",
            "Iteration 592, loss = 1.35292632\n",
            "Validation score: 0.569639\n",
            "Iteration 593, loss = 1.35009965\n",
            "Validation score: 0.573836\n",
            "Iteration 594, loss = 1.34215942\n",
            "Validation score: 0.575853\n",
            "Iteration 595, loss = 1.33800733\n",
            "Validation score: 0.577755\n",
            "Iteration 596, loss = 1.33089664\n",
            "Validation score: 0.578370\n",
            "Iteration 597, loss = 1.32952830\n",
            "Validation score: 0.581165\n",
            "Iteration 598, loss = 1.32093195\n",
            "Validation score: 0.581797\n",
            "Iteration 599, loss = 1.31702328\n",
            "Validation score: 0.584675\n",
            "Iteration 600, loss = 1.30836557\n",
            "Validation score: 0.584753\n",
            "Iteration 601, loss = 1.30307730\n",
            "Validation score: 0.588912\n",
            "Iteration 602, loss = 1.29570367\n",
            "Validation score: 0.590457\n",
            "Iteration 603, loss = 1.29054060\n",
            "Validation score: 0.593001\n",
            "Iteration 604, loss = 1.28571367\n",
            "Validation score: 0.594163\n",
            "Iteration 605, loss = 1.28338948\n",
            "Validation score: 0.597178\n",
            "Iteration 606, loss = 1.27019936\n",
            "Validation score: 0.597307\n",
            "Iteration 607, loss = 1.26223052\n",
            "Validation score: 0.601529\n",
            "Iteration 608, loss = 1.25615760\n",
            "Validation score: 0.600988\n",
            "Iteration 609, loss = 1.25029526\n",
            "Validation score: 0.604236\n",
            "Iteration 610, loss = 1.24300164\n",
            "Validation score: 0.606388\n",
            "Iteration 611, loss = 1.23311378\n",
            "Validation score: 0.610431\n",
            "Iteration 612, loss = 1.22589476\n",
            "Validation score: 0.611937\n",
            "Iteration 613, loss = 1.22163020\n",
            "Validation score: 0.616289\n",
            "Iteration 614, loss = 1.20982908\n",
            "Validation score: 0.618565\n",
            "Iteration 615, loss = 1.20153984\n",
            "Validation score: 0.616909\n",
            "Iteration 616, loss = 1.19314855\n",
            "Validation score: 0.622245\n",
            "Iteration 617, loss = 1.18606375\n",
            "Validation score: 0.626458\n",
            "Iteration 618, loss = 1.17749482\n",
            "Validation score: 0.629684\n",
            "Iteration 619, loss = 1.16661791\n",
            "Validation score: 0.630197\n",
            "Iteration 620, loss = 1.16248590\n",
            "Validation score: 0.632203\n",
            "Iteration 621, loss = 1.15112036\n",
            "Validation score: 0.638390\n",
            "Iteration 622, loss = 1.14543601\n",
            "Validation score: 0.638905\n",
            "Iteration 623, loss = 1.13565181\n",
            "Validation score: 0.643642\n",
            "Iteration 624, loss = 1.11974602\n",
            "Validation score: 0.647324\n",
            "Iteration 625, loss = 1.11174143\n",
            "Validation score: 0.650525\n",
            "Iteration 626, loss = 1.10603124\n",
            "Validation score: 0.650131\n",
            "Iteration 627, loss = 1.09428397\n",
            "Validation score: 0.654493\n",
            "Iteration 628, loss = 1.08064854\n",
            "Validation score: 0.659182\n",
            "Iteration 629, loss = 1.06904463\n",
            "Validation score: 0.661337\n",
            "Iteration 630, loss = 1.06070109\n",
            "Validation score: 0.663425\n",
            "Iteration 631, loss = 1.05329292\n",
            "Validation score: 0.670630\n",
            "Iteration 632, loss = 1.03982998\n",
            "Validation score: 0.672791\n",
            "Iteration 633, loss = 1.02781020\n",
            "Validation score: 0.674616\n",
            "Iteration 634, loss = 1.01893260\n",
            "Validation score: 0.679387\n",
            "Iteration 635, loss = 1.00624256\n",
            "Validation score: 0.683766\n",
            "Iteration 636, loss = 0.99550135\n",
            "Validation score: 0.688398\n",
            "Iteration 637, loss = 0.98349757\n",
            "Validation score: 0.687843\n",
            "Iteration 638, loss = 0.97648884\n",
            "Validation score: 0.694660\n",
            "Iteration 639, loss = 0.95994647\n",
            "Validation score: 0.699659\n",
            "Iteration 640, loss = 0.94879761\n",
            "Validation score: 0.700992\n",
            "Iteration 641, loss = 0.93561082\n",
            "Validation score: 0.707179\n",
            "Iteration 642, loss = 0.92419139\n",
            "Validation score: 0.710724\n",
            "Iteration 643, loss = 0.90962959\n",
            "Validation score: 0.709420\n",
            "Iteration 644, loss = 0.90680218\n",
            "Validation score: 0.717928\n",
            "Iteration 645, loss = 0.89115032\n",
            "Validation score: 0.712700\n",
            "Iteration 646, loss = 0.88143392\n",
            "Validation score: 0.725581\n",
            "Iteration 647, loss = 0.86074513\n",
            "Validation score: 0.729968\n",
            "Iteration 648, loss = 0.84728342\n",
            "Validation score: 0.735074\n",
            "Iteration 649, loss = 0.84112801\n",
            "Validation score: 0.737023\n",
            "Iteration 650, loss = 0.82528591\n",
            "Validation score: 0.743172\n",
            "Iteration 651, loss = 0.80666848\n",
            "Validation score: 0.746376\n",
            "Iteration 652, loss = 0.79597247\n",
            "Validation score: 0.747755\n",
            "Iteration 653, loss = 0.79322275\n",
            "Validation score: 0.754220\n",
            "Iteration 654, loss = 0.77367000\n",
            "Validation score: 0.754826\n",
            "Iteration 655, loss = 0.75734280\n",
            "Validation score: 0.764039\n",
            "Iteration 656, loss = 0.74243331\n",
            "Validation score: 0.768089\n",
            "Iteration 657, loss = 0.73492669\n",
            "Validation score: 0.772634\n",
            "Iteration 658, loss = 0.71665837\n",
            "Validation score: 0.775208\n",
            "Iteration 659, loss = 0.70426478\n",
            "Validation score: 0.778189\n",
            "Iteration 660, loss = 0.69294111\n",
            "Validation score: 0.785523\n",
            "Iteration 661, loss = 0.68223366\n",
            "Validation score: 0.789474\n",
            "Iteration 662, loss = 0.66134060\n",
            "Validation score: 0.793706\n",
            "Iteration 663, loss = 0.64984987\n",
            "Validation score: 0.798424\n",
            "Iteration 664, loss = 0.63731200\n",
            "Validation score: 0.802714\n",
            "Iteration 665, loss = 0.62296049\n",
            "Validation score: 0.805368\n",
            "Iteration 666, loss = 0.61162080\n",
            "Validation score: 0.809981\n",
            "Iteration 667, loss = 0.60546410\n",
            "Validation score: 0.811785\n",
            "Iteration 668, loss = 0.58525378\n",
            "Validation score: 0.819560\n",
            "Iteration 669, loss = 0.56918169\n",
            "Validation score: 0.823690\n",
            "Iteration 670, loss = 0.55481028\n",
            "Validation score: 0.827633\n",
            "Iteration 671, loss = 0.54547266\n",
            "Validation score: 0.828657\n",
            "Iteration 672, loss = 0.53127750\n",
            "Validation score: 0.832953\n",
            "Iteration 673, loss = 0.51856880\n",
            "Validation score: 0.840789\n",
            "Iteration 674, loss = 0.50683199\n",
            "Validation score: 0.843856\n",
            "Iteration 675, loss = 0.50015750\n",
            "Validation score: 0.835445\n",
            "Iteration 676, loss = 0.49091346\n",
            "Validation score: 0.852860\n",
            "Iteration 677, loss = 0.46330654\n",
            "Validation score: 0.856329\n",
            "Iteration 678, loss = 0.45313638\n",
            "Validation score: 0.860630\n",
            "Iteration 679, loss = 0.43933525\n",
            "Validation score: 0.864449\n",
            "Iteration 680, loss = 0.42890621\n",
            "Validation score: 0.868666\n",
            "Iteration 681, loss = 0.41659869\n",
            "Validation score: 0.872541\n",
            "Iteration 682, loss = 0.40302247\n",
            "Validation score: 0.876069\n",
            "Iteration 683, loss = 0.39419417\n",
            "Validation score: 0.880078\n",
            "Iteration 684, loss = 0.38245787\n",
            "Validation score: 0.882536\n",
            "Iteration 685, loss = 0.36664741\n",
            "Validation score: 0.886993\n",
            "Iteration 686, loss = 0.35501192\n",
            "Validation score: 0.891275\n",
            "Iteration 687, loss = 0.34684722\n",
            "Validation score: 0.894443\n",
            "Iteration 688, loss = 0.33726520\n",
            "Validation score: 0.898322\n",
            "Iteration 689, loss = 0.32237131\n",
            "Validation score: 0.901519\n",
            "Iteration 690, loss = 0.31051514\n",
            "Validation score: 0.905069\n",
            "Iteration 691, loss = 0.30714268\n",
            "Validation score: 0.895946\n",
            "Iteration 692, loss = 0.29677142\n",
            "Validation score: 0.911888\n",
            "Iteration 693, loss = 0.28186514\n",
            "Validation score: 0.912013\n",
            "Iteration 694, loss = 0.27061869\n",
            "Validation score: 0.918379\n",
            "Iteration 695, loss = 0.25991672\n",
            "Validation score: 0.921357\n",
            "Iteration 696, loss = 0.24900543\n",
            "Validation score: 0.924368\n",
            "Iteration 697, loss = 0.24107386\n",
            "Validation score: 0.924803\n",
            "Iteration 698, loss = 0.23536017\n",
            "Validation score: 0.929692\n",
            "Iteration 699, loss = 0.22033810\n",
            "Validation score: 0.933110\n",
            "Iteration 700, loss = 0.21212001\n",
            "Validation score: 0.935950\n",
            "Iteration 701, loss = 0.20435370\n",
            "Validation score: 0.938337\n",
            "Iteration 702, loss = 0.19887236\n",
            "Validation score: 0.939663\n",
            "Iteration 703, loss = 0.19383349\n",
            "Validation score: 0.942277\n",
            "Iteration 704, loss = 0.18229284\n",
            "Validation score: 0.945484\n",
            "Iteration 705, loss = 0.17241913\n",
            "Validation score: 0.948196\n",
            "Iteration 706, loss = 0.16289259\n",
            "Validation score: 0.949152\n",
            "Iteration 707, loss = 0.15684032\n",
            "Validation score: 0.952602\n",
            "Iteration 708, loss = 0.15126065\n",
            "Validation score: 0.955758\n",
            "Iteration 709, loss = 0.14240673\n",
            "Validation score: 0.957918\n",
            "Iteration 710, loss = 0.13669998\n",
            "Validation score: 0.958583\n",
            "Iteration 711, loss = 0.13055757\n",
            "Validation score: 0.960952\n",
            "Iteration 712, loss = 0.12567331\n",
            "Validation score: 0.961399\n",
            "Iteration 713, loss = 0.11870756\n",
            "Validation score: 0.965254\n",
            "Iteration 714, loss = 0.11179846\n",
            "Validation score: 0.967412\n",
            "Iteration 715, loss = 0.10646295\n",
            "Validation score: 0.966902\n",
            "Iteration 716, loss = 0.10166177\n",
            "Validation score: 0.970742\n",
            "Iteration 717, loss = 0.09507063\n",
            "Validation score: 0.972364\n",
            "Iteration 718, loss = 0.09210994\n",
            "Validation score: 0.973791\n",
            "Iteration 719, loss = 0.08574571\n",
            "Validation score: 0.973954\n",
            "Iteration 720, loss = 0.08251244\n",
            "Validation score: 0.976298\n",
            "Iteration 721, loss = 0.07602003\n",
            "Validation score: 0.977450\n",
            "Iteration 722, loss = 0.07281660\n",
            "Validation score: 0.979334\n",
            "Iteration 723, loss = 0.06911411\n",
            "Validation score: 0.980153\n",
            "Iteration 724, loss = 0.06657023\n",
            "Validation score: 0.981222\n",
            "Iteration 725, loss = 0.06236209\n",
            "Validation score: 0.982407\n",
            "Iteration 726, loss = 0.05932696\n",
            "Validation score: 0.983777\n",
            "Iteration 727, loss = 0.05618958\n",
            "Validation score: 0.984713\n",
            "Iteration 728, loss = 0.05200950\n",
            "Validation score: 0.985462\n",
            "Iteration 729, loss = 0.04859023\n",
            "Validation score: 0.985691\n",
            "Iteration 730, loss = 0.04673604\n",
            "Validation score: 0.987395\n",
            "Iteration 731, loss = 0.04344620\n",
            "Validation score: 0.987700\n",
            "Iteration 732, loss = 0.04079135\n",
            "Validation score: 0.988566\n",
            "Iteration 733, loss = 0.03893337\n",
            "Validation score: 0.989406\n",
            "Iteration 734, loss = 0.03670929\n",
            "Validation score: 0.989755\n",
            "Iteration 735, loss = 0.03827952\n",
            "Validation score: 0.988793\n",
            "Iteration 736, loss = 0.03463837\n",
            "Validation score: 0.989539\n",
            "Iteration 737, loss = 0.03109933\n",
            "Validation score: 0.991807\n",
            "Iteration 738, loss = 0.02867914\n",
            "Validation score: 0.992408\n",
            "Iteration 739, loss = 0.02784278\n",
            "Validation score: 0.992420\n",
            "Iteration 740, loss = 0.02656815\n",
            "Validation score: 0.993304\n",
            "Iteration 741, loss = 0.02473453\n",
            "Validation score: 0.993696\n",
            "Iteration 742, loss = 0.02352704\n",
            "Validation score: 0.994090\n",
            "Iteration 743, loss = 0.02231317\n",
            "Validation score: 0.994176\n",
            "Iteration 744, loss = 0.02190940\n",
            "Validation score: 0.994061\n",
            "Iteration 745, loss = 0.02098725\n",
            "Validation score: 0.994992\n",
            "Iteration 746, loss = 0.01973548\n",
            "Validation score: 0.995034\n",
            "Iteration 747, loss = 0.01896517\n",
            "Validation score: 0.994580\n",
            "Iteration 748, loss = 0.01828205\n",
            "Validation score: 0.995343\n",
            "Iteration 749, loss = 0.01689314\n",
            "Validation score: 0.995847\n",
            "Iteration 750, loss = 0.01641609\n",
            "Validation score: 0.996068\n",
            "Iteration 751, loss = 0.01555793\n",
            "Validation score: 0.996380\n",
            "Iteration 752, loss = 0.01496519\n",
            "Validation score: 0.996387\n",
            "Iteration 753, loss = 0.01489967\n",
            "Validation score: 0.995739\n",
            "Iteration 754, loss = 0.01456883\n",
            "Validation score: 0.996209\n",
            "Iteration 755, loss = 0.01434239\n",
            "Validation score: 0.996850\n",
            "Iteration 756, loss = 0.01404061\n",
            "Validation score: 0.996761\n",
            "Iteration 757, loss = 0.01359931\n",
            "Validation score: 0.996913\n",
            "Iteration 758, loss = 0.01342386\n",
            "Validation score: 0.996968\n",
            "Iteration 759, loss = 0.01277372\n",
            "Validation score: 0.997295\n",
            "Iteration 760, loss = 0.01238378\n",
            "Validation score: 0.997171\n",
            "Iteration 761, loss = 0.01164924\n",
            "Validation score: 0.997456\n",
            "Iteration 762, loss = 0.01189568\n",
            "Validation score: 0.997337\n",
            "Iteration 763, loss = 0.01159970\n",
            "Validation score: 0.997401\n",
            "Iteration 764, loss = 0.01169116\n",
            "Validation score: 0.997614\n",
            "Iteration 765, loss = 0.01135162\n",
            "Validation score: 0.997095\n",
            "Iteration 766, loss = 0.01123650\n",
            "Validation score: 0.996849\n",
            "Iteration 767, loss = 0.01143865\n",
            "Validation score: 0.997539\n",
            "Iteration 768, loss = 0.01099831\n",
            "Validation score: 0.997620\n",
            "Iteration 769, loss = 0.01082051\n",
            "Validation score: 0.997259\n",
            "Iteration 770, loss = 0.01058899\n",
            "Validation score: 0.997814\n",
            "Iteration 771, loss = 0.01056317\n",
            "Validation score: 0.997760\n",
            "Iteration 772, loss = 0.01075496\n",
            "Validation score: 0.996969\n",
            "Iteration 773, loss = 0.01024269\n",
            "Validation score: 0.997826\n",
            "Iteration 774, loss = 0.01053205\n",
            "Validation score: 0.997786\n",
            "Iteration 775, loss = 0.01022635\n",
            "Validation score: 0.997790\n",
            "Iteration 776, loss = 0.01041474\n",
            "Validation score: 0.997574\n",
            "Iteration 777, loss = 0.01069257\n",
            "Validation score: 0.997912\n",
            "Iteration 778, loss = 0.01036622\n",
            "Validation score: 0.997668\n",
            "Iteration 779, loss = 0.01050391\n",
            "Validation score: 0.997556\n",
            "Iteration 780, loss = 0.01008932\n",
            "Validation score: 0.997850\n",
            "Iteration 781, loss = 0.01037150\n",
            "Validation score: 0.997805\n",
            "Iteration 782, loss = 0.00986149\n",
            "Validation score: 0.997862\n",
            "Iteration 783, loss = 0.01043538\n",
            "Validation score: 0.997872\n",
            "Iteration 784, loss = 0.01010780\n",
            "Validation score: 0.997860\n",
            "Iteration 785, loss = 0.01027796\n",
            "Validation score: 0.997286\n",
            "Iteration 786, loss = 0.01033433\n",
            "Validation score: 0.997830\n",
            "Iteration 787, loss = 0.01048570\n",
            "Validation score: 0.997532\n",
            "Iteration 788, loss = 0.01024432\n",
            "Validation score: 0.997529\n",
            "Iteration 789, loss = 0.01054593\n",
            "Validation score: 0.997938\n",
            "Iteration 790, loss = 0.01003397\n",
            "Validation score: 0.997948\n",
            "Iteration 791, loss = 0.01011538\n",
            "Validation score: 0.997928\n",
            "Iteration 792, loss = 0.01032183\n",
            "Validation score: 0.997841\n",
            "Iteration 793, loss = 0.01088318\n",
            "Validation score: 0.997141\n",
            "Iteration 794, loss = 0.01038546\n",
            "Validation score: 0.997786\n",
            "Iteration 795, loss = 0.01092234\n",
            "Validation score: 0.997960\n",
            "Iteration 796, loss = 0.01008875\n",
            "Validation score: 0.997860\n",
            "Iteration 797, loss = 0.01009116\n",
            "Validation score: 0.997541\n",
            "Iteration 798, loss = 0.01002748\n",
            "Validation score: 0.997780\n",
            "Iteration 799, loss = 0.01027256\n",
            "Validation score: 0.997759\n",
            "Iteration 800, loss = 0.01083404\n",
            "Validation score: 0.997944\n",
            "Iteration 801, loss = 0.01057671\n",
            "Validation score: 0.997898\n",
            "Iteration 802, loss = 0.01003839\n",
            "Validation score: 0.997693\n",
            "Iteration 803, loss = 0.01104873\n",
            "Validation score: 0.996829\n",
            "Iteration 804, loss = 0.01002143\n",
            "Validation score: 0.997870\n",
            "Iteration 805, loss = 0.01027235\n",
            "Validation score: 0.996986\n",
            "Iteration 806, loss = 0.01078512\n",
            "Validation score: 0.997961\n",
            "Iteration 807, loss = 0.00974869\n",
            "Validation score: 0.997807\n",
            "Iteration 808, loss = 0.01029809\n",
            "Validation score: 0.997497\n",
            "Iteration 809, loss = 0.01038719\n",
            "Validation score: 0.997901\n",
            "Iteration 810, loss = 0.01041165\n",
            "Validation score: 0.997644\n",
            "Iteration 811, loss = 0.00994011\n",
            "Validation score: 0.997600\n",
            "Iteration 812, loss = 0.01015472\n",
            "Validation score: 0.997931\n",
            "Iteration 813, loss = 0.01010360\n",
            "Validation score: 0.997831\n",
            "Iteration 814, loss = 0.01035311\n",
            "Validation score: 0.997918\n",
            "Iteration 815, loss = 0.01004627\n",
            "Validation score: 0.997827\n",
            "Iteration 816, loss = 0.00981118\n",
            "Validation score: 0.997882\n",
            "Iteration 817, loss = 0.01002188\n",
            "Validation score: 0.997628\n",
            "Iteration 818, loss = 0.01013399\n",
            "Validation score: 0.997877\n",
            "Iteration 819, loss = 0.01047119\n",
            "Validation score: 0.997901\n",
            "Iteration 820, loss = 0.01028041\n",
            "Validation score: 0.997965\n",
            "Iteration 821, loss = 0.01045728\n",
            "Validation score: 0.997903\n",
            "Iteration 822, loss = 0.00983779\n",
            "Validation score: 0.997667\n",
            "Iteration 823, loss = 0.00991515\n",
            "Validation score: 0.997915\n",
            "Iteration 824, loss = 0.00984682\n",
            "Validation score: 0.997657\n",
            "Iteration 825, loss = 0.01055890\n",
            "Validation score: 0.997071\n",
            "Iteration 826, loss = 0.01071484\n",
            "Validation score: 0.997576\n",
            "Iteration 827, loss = 0.01056452\n",
            "Validation score: 0.997402\n",
            "Iteration 828, loss = 0.01046790\n",
            "Validation score: 0.997418\n",
            "Iteration 829, loss = 0.01006185\n",
            "Validation score: 0.997922\n",
            "Iteration 830, loss = 0.01028423\n",
            "Validation score: 0.997536\n",
            "Iteration 831, loss = 0.01081716\n",
            "Validation score: 0.997869\n",
            "Iteration 832, loss = 0.01044007\n",
            "Validation score: 0.997677\n",
            "Iteration 833, loss = 0.01009692\n",
            "Validation score: 0.997934\n",
            "Iteration 834, loss = 0.00996056\n",
            "Validation score: 0.997811\n",
            "Iteration 835, loss = 0.01049293\n",
            "Validation score: 0.997663\n",
            "Iteration 836, loss = 0.00977037\n",
            "Validation score: 0.997541\n",
            "Iteration 837, loss = 0.00997202\n",
            "Validation score: 0.997673\n",
            "Iteration 838, loss = 0.01027240\n",
            "Validation score: 0.997594\n",
            "Iteration 839, loss = 0.01028732\n",
            "Validation score: 0.997786\n",
            "Iteration 840, loss = 0.01012071\n",
            "Validation score: 0.997252\n",
            "Iteration 841, loss = 0.01058391\n",
            "Validation score: 0.997515\n",
            "Iteration 842, loss = 0.01005773\n",
            "Validation score: 0.997331\n",
            "Iteration 843, loss = 0.01121534\n",
            "Validation score: 0.997268\n",
            "Iteration 844, loss = 0.01038249\n",
            "Validation score: 0.997405\n",
            "Iteration 845, loss = 0.01014558\n",
            "Validation score: 0.997848\n",
            "Iteration 846, loss = 0.01054591\n",
            "Validation score: 0.997257\n",
            "Iteration 847, loss = 0.01060982\n",
            "Validation score: 0.997532\n",
            "Iteration 848, loss = 0.01021259\n",
            "Validation score: 0.997671\n",
            "Iteration 849, loss = 0.01000048\n",
            "Validation score: 0.997369\n",
            "Iteration 850, loss = 0.01155664\n",
            "Validation score: 0.997850\n",
            "Iteration 851, loss = 0.01011124\n",
            "Validation score: 0.997718\n",
            "Iteration 852, loss = 0.01032468\n",
            "Validation score: 0.997706\n",
            "Iteration 853, loss = 0.00989020\n",
            "Validation score: 0.997897\n",
            "Iteration 854, loss = 0.01013793\n",
            "Validation score: 0.996948\n",
            "Iteration 855, loss = 0.01010788\n",
            "Validation score: 0.997887\n",
            "Iteration 856, loss = 0.01094577\n",
            "Validation score: 0.997260\n",
            "Iteration 857, loss = 0.01020614\n",
            "Validation score: 0.997852\n",
            "Iteration 858, loss = 0.01021271\n",
            "Validation score: 0.997615\n",
            "Iteration 859, loss = 0.00980998\n",
            "Validation score: 0.997843\n",
            "Iteration 860, loss = 0.01018563\n",
            "Validation score: 0.997846\n",
            "Iteration 861, loss = 0.01040456\n",
            "Validation score: 0.997777\n",
            "Iteration 862, loss = 0.01046798\n",
            "Validation score: 0.997386\n",
            "Iteration 863, loss = 0.01095609\n",
            "Validation score: 0.996914\n",
            "Iteration 864, loss = 0.01142675\n",
            "Validation score: 0.996465\n",
            "Iteration 865, loss = 0.01022053\n",
            "Validation score: 0.997537\n",
            "Iteration 866, loss = 0.01061515\n",
            "Validation score: 0.997423\n",
            "Iteration 867, loss = 0.01023337\n",
            "Validation score: 0.997715\n",
            "Iteration 868, loss = 0.01016227\n",
            "Validation score: 0.997443\n",
            "Iteration 869, loss = 0.01016206\n",
            "Validation score: 0.997725\n",
            "Iteration 870, loss = 0.01032742\n",
            "Validation score: 0.997852\n",
            "Iteration 871, loss = 0.00977183\n",
            "Validation score: 0.997892\n",
            "Validation score did not improve more than tol=0.000100 for 100 consecutive epochs. Stopping.\n",
            "Regression score:  0.9979457760230287\n",
            "true: \n",
            "[[-2.22926171  0.37054151]\n",
            " [ 1.37192022 -3.34726184]\n",
            " [ 3.94648432  2.31802132]\n",
            " [ 4.48505117  0.02339325]]\n",
            "predicted:\n",
            "[[-2.28043917  0.35371193]\n",
            " [ 1.32251524 -3.44419629]\n",
            " [ 3.86846395  2.08628618]\n",
            " [ 4.64613577  0.04125043]]\n",
            "Regression score:  0.9980158839685347\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}